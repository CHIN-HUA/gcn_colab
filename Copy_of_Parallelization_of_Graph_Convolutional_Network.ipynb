{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNYCdSYsTrO42SRPtPERJQ4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/CHIN-HUA/gcn_colab/blob/main/Copy_of_Parallelization_of_Graph_Convolutional_Network.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hGnP66582INd",
        "outputId": "007aa3b5-007f-4ca0-b144-8aa57b4ccee7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "bin    cuda\tcuda-11.8  games\t       include\tlib64\t   man\t share\n",
            "colab  cuda-11\tetc\t   _gcs_config_ops.so  lib\tlicensing  sbin  src\n"
          ]
        }
      ],
      "source": [
        "# To show that if there is cuda tookit installed\n",
        "!ls /usr/local"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# To show that if there is cuda tookit installed\n",
        "!ls /usr/local"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nmu0aDLV2Nb3",
        "outputId": "33f20ad4-41ec-4f13-e41b-c4ab657e1348"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "bin    cuda\tcuda-11.8  games\t       include\tlib64\t   man\t share\n",
            "colab  cuda-11\tetc\t   _gcs_config_ops.so  lib\tlicensing  sbin  src\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# To show the property of the nvidia card(On my one, I use the K80)\n",
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UpnOyBkV2Pho",
        "outputId": "f587784c-fc2c-432e-b075-2446913b0e64"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mon May 15 14:41:50 2023       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 525.85.12    Driver Version: 525.85.12    CUDA Version: 12.0     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   50C    P8    10W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Write a cu file contain the host and kernel code\n",
        "%%writefile hello.cu\n",
        "\n",
        "#include <iostream>\n",
        "#include <cuda.h>\n",
        "\n",
        "__global__ void hello(void)\n",
        "{\n",
        "  printf(\"GPU: Hello!\\n\");\n",
        "}\n",
        "int main(int argc,char **argv)\n",
        "{\n",
        "  printf(\"CPU: Hello!\\n\");\n",
        "  hello<<<1,10>>>();\n",
        "  cudaDeviceReset();\n",
        "  return 0;\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LxYiEwi96kgc",
        "outputId": "3edaf0b6-c693-4e56-9614-5edb7bff7511"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting hello.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc -Wno-deprecated-gpu-targets hello.cu -o hello\n",
        "\n",
        "!./hello"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yYwH42En7Awq",
        "outputId": "38b1562e-9c83-4851-da25-d7d5c7d2a35e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU: Hello!\n",
            "GPU: Hello!\n",
            "GPU: Hello!\n",
            "GPU: Hello!\n",
            "GPU: Hello!\n",
            "GPU: Hello!\n",
            "GPU: Hello!\n",
            "GPU: Hello!\n",
            "GPU: Hello!\n",
            "GPU: Hello!\n",
            "GPU: Hello!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "MIT License\n",
        "Copyright (c) 2020 Ronald Seoh\n",
        "Permission is hereby granted, free of charge, to any person obtaining a copy\n",
        "of this software and associated documentation files (the \"Software\"), to deal\n",
        "in the Software without restriction, including without limitation the rights\n",
        "to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n",
        "copies of the Software, and to permit persons to whom the Software is\n",
        "furnished to do so, subject to the following conditions:\n",
        "The above copyright notice and this permission notice shall be included in all\n",
        "copies or substantial portions of the Software.\n",
        "THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n",
        "IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n",
        "FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n",
        "AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n",
        "LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n",
        "OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\n",
        "SOFTWARE.\n",
        "'''\n",
        "\n",
        "# torch.device / CUDA Setup\n",
        "import torch\n",
        "\n",
        "use_cuda = True\n",
        "use_colab_tpu = False\n",
        "colab_tpu_available = False\n",
        "\n",
        "if use_colab_tpu:\n",
        "    try:\n",
        "        assert os.environ['COLAB_TPU_ADDR']\n",
        "        colab_tpu_available = True\n",
        "    except:\n",
        "        colab_tpu_available = True\n",
        "\n",
        "if use_cuda and torch.cuda.is_available():\n",
        "    torch_device = torch.device('cuda')\n",
        "\n",
        "    # Set this to True to make your output immediately reproducible\n",
        "    # Note: https://pytorch.org/docs/stable/notes/randomness.html\n",
        "    torch.backends.cudnn.deterministic = False\n",
        "\n",
        "    # Disable 'benchmark' mode: Set this False if you want to measure running times more fairly\n",
        "    # Note: https://discuss.pytorch.org/t/what-does-torch-backends-cudnn-benchmark-do/5936\n",
        "    torch.backends.cudnn.benchmark = True\n",
        "\n",
        "    # Faster Host to GPU copies with page-locked memory\n",
        "    use_pin_memory = True\n",
        "\n",
        "    # CUDA libraries version information\n",
        "    print(\"CUDA Version: \" + str(torch.version.cuda))\n",
        "    print(\"cuDNN Version: \" + str(torch.backends.cudnn.version()))\n",
        "    print(\"CUDA Device Name: \" + str(torch.cuda.get_device_name()))\n",
        "    print(\"CUDA Capabilities: \"+ str(torch.cuda.get_device_capability()))\n",
        "\n",
        "elif use_colab_tpu and colab_tpu_available:\n",
        "    # This needs to be installed separately\n",
        "    # https://github.com/pytorch/xla/blob/master/contrib/colab/getting-started.ipynb\n",
        "    import torch_xla\n",
        "    import torch_xla.core.xla_model as xm\n",
        "\n",
        "    torch_device = xm.xla_device()\n",
        "\n",
        "else:\n",
        "    torch_device = torch.device('cpu')\n",
        "    use_pin_memory = False"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JxirNJYl754r",
        "outputId": "d917708f-fc42-4c43-d90d-14cc1dafe719"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CUDA Version: 11.8\n",
            "cuDNN Version: 8700\n",
            "CUDA Device Name: Tesla T4\n",
            "CUDA Capabilities: (7, 5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/hengdashi/cuda_gcn.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TbSpnYZY81FT",
        "outputId": "1523505c-77ad-477c-c36d-54c6e32c284b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'cuda_gcn'...\n",
            "remote: Enumerating objects: 425, done.\u001b[K\n",
            "remote: Counting objects: 100% (15/15), done.\u001b[K\n",
            "remote: Compressing objects: 100% (11/11), done.\u001b[K\n",
            "remote: Total 425 (delta 4), reused 13 (delta 4), pack-reused 410\u001b[K\n",
            "Receiving objects: 100% (425/425), 21.89 MiB | 24.63 MiB/s, done.\n",
            "Resolving deltas: 100% (230/230), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls ./cuda_gcn/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lndgcMHs9oZO",
        "outputId": "bbdd442d-113c-4784-eb84-ec8655662f38"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "data.tgz  Makefile  README.md  reddit_preprocess.py  report  src\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls\n",
        "! ls cuda_gcn\n",
        "! cd cuda_gcn && make cuda"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "USmVhXMYCkCJ",
        "outputId": "085ee750-52d6-49fc-bec4-37844393a0ac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda_gcn  sample_data\n",
            "data.tgz  Makefile  README.md  reddit_preprocess.py  report  src\n",
            "nvcc -dc -O3 -std=c++11 -Isrc -Isrc/common -Isrc/seq -Isrc/cuda src/main.cpp -o src/cudamain.o\n",
            "In file included from \u001b[01m\u001b[K/usr/local/cuda/bin/../targets/x86_64-linux/include/thrust/detail/config/config.h:27\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/cuda/bin/../targets/x86_64-linux/include/thrust/detail/config.h:23\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/cuda/bin/../targets/x86_64-linux/include/thrust/extrema.h:23\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Ksrc/cuda/cuda_kernel.cuh:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Ksrc/cuda/cuda_variable.cuh:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Ksrc/cuda/cuda_gcn.cuh:5\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Ksrc/main.cpp:10\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/cuda/bin/../targets/x86_64-linux/include/thrust/detail/config/cpp_dialect.h:131:13:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[KThrust requires at least C++14. C++11 is deprecated but still supported. C++11 support will be removed in a future release. Define THRUST_IGNORE_DEPRECATED_CPP_DIALECT to suppress this message.\n",
            "  131 |      THRUST_\u001b[01;35m\u001b[KCOMPILER_DEPRECATION_SOFT(C++14, C++11);\u001b[m\u001b[K\n",
            "      |             \u001b[01;35m\u001b[K^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K                                                                                                                                                           \n",
            "In file included from \u001b[01m\u001b[K/usr/local/cuda/bin/../targets/x86_64-linux/include/cub/util_arch.cuh:36\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/cuda/bin/../targets/x86_64-linux/include/thrust/system/cuda/detail/copy.h:35\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/cuda/bin/../targets/x86_64-linux/include/thrust/system/detail/adl/copy.h:42\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/cuda/bin/../targets/x86_64-linux/include/thrust/detail/copy.inl:22\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/cuda/bin/../targets/x86_64-linux/include/thrust/detail/copy.h:90\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/cuda/bin/../targets/x86_64-linux/include/thrust/system/detail/sequential/merge.inl:19\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/cuda/bin/../targets/x86_64-linux/include/thrust/system/detail/sequential/merge.h:78\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/cuda/bin/../targets/x86_64-linux/include/thrust/system/cpp/detail/merge.h:22\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/cuda/bin/../targets/x86_64-linux/include/thrust/system/cpp/execution_policy.h:51\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/cuda/bin/../targets/x86_64-linux/include/thrust/execution_policy.h:32\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/cuda/bin/../targets/x86_64-linux/include/thrust/detail/get_iterator_value.h:20\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/cuda/bin/../targets/x86_64-linux/include/thrust/system/detail/generic/extrema.inl:25\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/cuda/bin/../targets/x86_64-linux/include/thrust/system/detail/generic/extrema.h:87\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/cuda/bin/../targets/x86_64-linux/include/thrust/detail/extrema.inl:22\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/cuda/bin/../targets/x86_64-linux/include/thrust/extrema.h:800\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Ksrc/cuda/cuda_kernel.cuh:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Ksrc/cuda/cuda_variable.cuh:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Ksrc/cuda/cuda_gcn.cuh:5\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Ksrc/main.cpp:10\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/cuda/bin/../targets/x86_64-linux/include/cub/util_cpp_dialect.cuh:142:13:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[KCUB requires at least C++14. C++11 is deprecated but still supported. C++11 support will be removed in a future release. Define CUB_IGNORE_DEPRECATED_CPP_DIALECT to suppress this message.\n",
            "  142 |      CUB_COM\u001b[01;35m\u001b[KPILER_DEPRECATION_SOFT(C++14, C++11);\u001b[m\u001b[K\n",
            "      |             \u001b[01;35m\u001b[K^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K                                                                                                                                                        \n",
            "g++ -c -O3 -std=c++11 -Isrc -Isrc/common -Isrc/seq -Isrc/cuda -Wall -Wno-sign-compare -Wno-unused-variable -Wno-unknown-pragmas src/common/parser.cpp -o src/common/parser.o\n",
            "g++ -c -O3 -std=c++11 -Isrc -Isrc/common -Isrc/seq -Isrc/cuda -Wall -Wno-sign-compare -Wno-unused-variable -Wno-unknown-pragmas src/common/timer.cpp -o src/common/timer.o\n",
            "g++ -c -O3 -std=c++11 -Isrc -Isrc/common -Isrc/seq -Isrc/cuda -Wall -Wno-sign-compare -Wno-unused-variable -Wno-unknown-pragmas src/seq/gcn.cpp -o src/seq/gcn.o\n",
            "g++ -c -O3 -std=c++11 -Isrc -Isrc/common -Isrc/seq -Isrc/cuda -Wall -Wno-sign-compare -Wno-unused-variable -Wno-unknown-pragmas src/seq/module.cpp -o src/seq/module.o\n",
            "g++ -c -O3 -std=c++11 -Isrc -Isrc/common -Isrc/seq -Isrc/cuda -Wall -Wno-sign-compare -Wno-unused-variable -Wno-unknown-pragmas src/seq/optim.cpp -o src/seq/optim.o\n",
            "g++ -c -O3 -std=c++11 -Isrc -Isrc/common -Isrc/seq -Isrc/cuda -Wall -Wno-sign-compare -Wno-unused-variable -Wno-unknown-pragmas src/seq/rand.cpp -o src/seq/rand.o\n",
            "g++ -c -O3 -std=c++11 -Isrc -Isrc/common -Isrc/seq -Isrc/cuda -Wall -Wno-sign-compare -Wno-unused-variable -Wno-unknown-pragmas src/seq/sparse.cpp -o src/seq/sparse.o\n",
            "g++ -c -O3 -std=c++11 -Isrc -Isrc/common -Isrc/seq -Isrc/cuda -Wall -Wno-sign-compare -Wno-unused-variable -Wno-unknown-pragmas src/seq/variable.cpp -o src/seq/variable.o\n",
            "nvcc -dc -O3 -std=c++11 -Isrc -Isrc/common -Isrc/seq -Isrc/cuda src/cuda/cuda_gcn.cu -o src/cuda/cuda_gcn.o\n",
            "In file included from \u001b[01m\u001b[K/usr/local/cuda/bin/../targets/x86_64-linux/include/thrust/detail/config/config.h:27\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/cuda/bin/../targets/x86_64-linux/include/thrust/detail/config.h:23\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/cuda/bin/../targets/x86_64-linux/include/thrust/extrema.h:23\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Ksrc/cuda/cuda_kernel.cuh:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Ksrc/cuda/cuda_variable.cuh:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Ksrc/cuda/cuda_gcn.cuh:5\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Ksrc/cuda/cuda_gcn.cu:1\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/cuda/bin/../targets/x86_64-linux/include/thrust/detail/config/cpp_dialect.h:131:13:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[KThrust requires at least C++14. C++11 is deprecated but still supported. C++11 support will be removed in a future release. Define THRUST_IGNORE_DEPRECATED_CPP_DIALECT to suppress this message.\n",
            "  131 |      THRUST_\u001b[01;35m\u001b[KCOMPILER_DEPRECATION_SOFT(C++14, C++11);\u001b[m\u001b[K\n",
            "      |             \u001b[01;35m\u001b[K^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K                                                                                                                                                           \n",
            "In file included from \u001b[01m\u001b[K/usr/local/cuda/bin/../targets/x86_64-linux/include/cub/util_arch.cuh:36\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/cuda/bin/../targets/x86_64-linux/include/cub/detail/device_synchronize.cuh:20\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/cuda/bin/../targets/x86_64-linux/include/thrust/system/cuda/detail/util.h:36\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/cuda/bin/../targets/x86_64-linux/include/thrust/system/cuda/detail/for_each.h:35\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/cuda/bin/../targets/x86_64-linux/include/thrust/system/detail/adl/for_each.h:42\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/cuda/bin/../targets/x86_64-linux/include/thrust/detail/for_each.inl:27\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/cuda/bin/../targets/x86_64-linux/include/thrust/for_each.h:277\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/cuda/bin/../targets/x86_64-linux/include/thrust/system/detail/generic/transform.inl:19\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/cuda/bin/../targets/x86_64-linux/include/thrust/system/detail/generic/transform.h:104\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/cuda/bin/../targets/x86_64-linux/include/thrust/detail/transform.inl:27\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/cuda/bin/../targets/x86_64-linux/include/thrust/transform.h:721\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/cuda/bin/../targets/x86_64-linux/include/thrust/system/detail/generic/copy.inl:23\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/cuda/bin/../targets/x86_64-linux/include/thrust/system/detail/generic/copy.h:57\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/cuda/bin/../targets/x86_64-linux/include/thrust/detail/copy.inl:21\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/cuda/bin/../targets/x86_64-linux/include/thrust/detail/copy.h:90\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/cuda/bin/../targets/x86_64-linux/include/thrust/system/detail/sequential/merge.inl:19\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/cuda/bin/../targets/x86_64-linux/include/thrust/system/detail/sequential/merge.h:78\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/cuda/bin/../targets/x86_64-linux/include/thrust/system/cpp/detail/merge.h:22\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/cuda/bin/../targets/x86_64-linux/include/thrust/system/cpp/execution_policy.h:51\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/cuda/bin/../targets/x86_64-linux/include/thrust/execution_policy.h:32\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/cuda/bin/../targets/x86_64-linux/include/thrust/detail/get_iterator_value.h:20\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/cuda/bin/../targets/x86_64-linux/include/thrust/system/detail/generic/extrema.inl:25\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/cuda/bin/../targets/x86_64-linux/include/thrust/system/detail/generic/extrema.h:87\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/cuda/bin/../targets/x86_64-linux/include/thrust/detail/extrema.inl:22\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/cuda/bin/../targets/x86_64-linux/include/thrust/extrema.h:800\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Ksrc/cuda/cuda_kernel.cuh:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Ksrc/cuda/cuda_variable.cuh:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Ksrc/cuda/cuda_gcn.cuh:5\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Ksrc/cuda/cuda_gcn.cu:1\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/cuda/bin/../targets/x86_64-linux/include/cub/util_cpp_dialect.cuh:142:13:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[KCUB requires at least C++14. C++11 is deprecated but still supported. C++11 support will be removed in a future release. Define CUB_IGNORE_DEPRECATED_CPP_DIALECT to suppress this message.\n",
            "  142 |      CUB_COM\u001b[01;35m\u001b[KPILER_DEPRECATION_SOFT(C++14, C++11);\u001b[m\u001b[K\n",
            "      |             \u001b[01;35m\u001b[K^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K                                                                                                                                                        \n",
            "In file included from \u001b[01m\u001b[K/usr/local/cuda/bin/../targets/x86_64-linux/include/thrust/detail/config/config.h:27\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/cuda/bin/../targets/x86_64-linux/include/thrust/detail/config.h:23\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/cuda/bin/../targets/x86_64-linux/include/thrust/extrema.h:23\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Ksrc/cuda/cuda_kernel.cuh:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Ksrc/cuda/cuda_variable.cuh:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Ksrc/cuda/cuda_gcn.cuh:5\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Ksrc/cuda/cuda_gcn.cu:1\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/cuda/bin/../targets/x86_64-linux/include/thrust/detail/config/cpp_dialect.h:131:13:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[KThrust requires at least C++14. C++11 is deprecated but still supported. C++11 support will be removed in a future release. Define THRUST_IGNORE_DEPRECATED_CPP_DIALECT to suppress this message.\n",
            "  131 |      THRUST_\u001b[01;35m\u001b[KCOMPILER_DEPRECATION_SOFT(C++14, C++11);\u001b[m\u001b[K\n",
            "      |             \u001b[01;35m\u001b[K^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K                                                                                                                                                           \n",
            "In file included from \u001b[01m\u001b[K/usr/local/cuda/bin/../targets/x86_64-linux/include/cub/util_arch.cuh:36\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/cuda/bin/../targets/x86_64-linux/include/cub/detail/device_synchronize.cuh:20\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/cuda/bin/../targets/x86_64-linux/include/thrust/system/cuda/detail/util.h:36\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/cuda/bin/../targets/x86_64-linux/include/thrust/system/cuda/detail/for_each.h:35\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/cuda/bin/../targets/x86_64-linux/include/thrust/system/detail/adl/for_each.h:42\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/cuda/bin/../targets/x86_64-linux/include/thrust/detail/for_each.inl:27\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/cuda/bin/../targets/x86_64-linux/include/thrust/for_each.h:277\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/cuda/bin/../targets/x86_64-linux/include/thrust/system/detail/generic/transform.inl:19\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/cuda/bin/../targets/x86_64-linux/include/thrust/system/detail/generic/transform.h:104\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/cuda/bin/../targets/x86_64-linux/include/thrust/detail/transform.inl:27\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/cuda/bin/../targets/x86_64-linux/include/thrust/transform.h:721\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/cuda/bin/../targets/x86_64-linux/include/thrust/system/detail/generic/copy.inl:23\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/cuda/bin/../targets/x86_64-linux/include/thrust/system/detail/generic/copy.h:57\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/cuda/bin/../targets/x86_64-linux/include/thrust/detail/copy.inl:21\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/cuda/bin/../targets/x86_64-linux/include/thrust/detail/copy.h:90\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/cuda/bin/../targets/x86_64-linux/include/thrust/system/detail/sequential/merge.inl:19\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/cuda/bin/../targets/x86_64-linux/include/thrust/system/detail/sequential/merge.h:78\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/cuda/bin/../targets/x86_64-linux/include/thrust/system/cpp/detail/merge.h:22\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/cuda/bin/../targets/x86_64-linux/include/thrust/system/cpp/execution_policy.h:51\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/cuda/bin/../targets/x86_64-linux/include/thrust/execution_policy.h:32\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/cuda/bin/../targets/x86_64-linux/include/thrust/detail/get_iterator_value.h:20\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/cuda/bin/../targets/x86_64-linux/include/thrust/system/detail/generic/extrema.inl:25\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/cuda/bin/../targets/x86_64-linux/include/thrust/system/detail/generic/extrema.h:87\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/cuda/bin/../targets/x86_64-linux/include/thrust/detail/extrema.inl:22\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/cuda/bin/../targets/x86_64-linux/include/thrust/extrema.h:800\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Ksrc/cuda/cuda_kernel.cuh:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Ksrc/cuda/cuda_variable.cuh:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Ksrc/cuda/cuda_gcn.cuh:5\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Ksrc/cuda/cuda_gcn.cu:1\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/cuda/bin/../targets/x86_64-linux/include/cub/util_cpp_dialect.cuh:142:13:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[KCUB requires at least C++14. C++11 is deprecated but still supported. C++11 support will be removed in a future release. Define CUB_IGNORE_DEPRECATED_CPP_DIALECT to suppress this message.\n",
            "  142 |      CUB_COM\u001b[01;35m\u001b[KPILER_DEPRECATION_SOFT(C++14, C++11);\u001b[m\u001b[K\n",
            "      |             \u001b[01;35m\u001b[K^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K                                                                                                                                                        \n",
            "nvcc -dc -O3 -std=c++11 -Isrc -Isrc/common -Isrc/seq -Isrc/cuda src/cuda/cuda_kernel.cu -o src/cuda/cuda_kernel.o\n",
            "In file included from \u001b[01m\u001b[K/usr/local/cuda/bin/../targets/x86_64-linux/include/thrust/detail/config/config.h:27\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/cuda/bin/../targets/x86_64-linux/include/thrust/detail/config.h:23\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/cuda/bin/../targets/x86_64-linux/include/thrust/extrema.h:23\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Ksrc/cuda/cuda_kernel.cuh:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Ksrc/cuda/cuda_kernel.cu:1\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/cuda/bin/../targets/x86_64-linux/include/thrust/detail/config/cpp_dialect.h:131:13:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[KThrust requires at least C++14. C++11 is deprecated but still supported. C++11 support will be removed in a future release. Define THRUST_IGNORE_DEPRECATED_CPP_DIALECT to suppress this message.\n",
            "  131 |      THRUST_\u001b[01;35m\u001b[KCOMPILER_DEPRECATION_SOFT(C++14, C++11);\u001b[m\u001b[K\n",
            "      |             \u001b[01;35m\u001b[K^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K                                                                                                                                                           \n",
            "In file included from \u001b[01m\u001b[K/usr/local/cuda/bin/../targets/x86_64-linux/include/cub/util_arch.cuh:36\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/cuda/bin/../targets/x86_64-linux/include/cub/detail/device_synchronize.cuh:20\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/cuda/bin/../targets/x86_64-linux/include/thrust/system/cuda/detail/util.h:36\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/cuda/bin/../targets/x86_64-linux/include/thrust/system/cuda/detail/for_each.h:35\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/cuda/bin/../targets/x86_64-linux/include/thrust/system/detail/adl/for_each.h:42\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/cuda/bin/../targets/x86_64-linux/include/thrust/detail/for_each.inl:27\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/cuda/bin/../targets/x86_64-linux/include/thrust/for_each.h:277\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/cuda/bin/../targets/x86_64-linux/include/thrust/system/detail/generic/transform.inl:19\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/cuda/bin/../targets/x86_64-linux/include/thrust/system/detail/generic/transform.h:104\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/cuda/bin/../targets/x86_64-linux/include/thrust/detail/transform.inl:27\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/cuda/bin/../targets/x86_64-linux/include/thrust/transform.h:721\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/cuda/bin/../targets/x86_64-linux/include/thrust/system/detail/generic/copy.inl:23\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/cuda/bin/../targets/x86_64-linux/include/thrust/system/detail/generic/copy.h:57\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/cuda/bin/../targets/x86_64-linux/include/thrust/detail/copy.inl:21\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/cuda/bin/../targets/x86_64-linux/include/thrust/detail/copy.h:90\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/cuda/bin/../targets/x86_64-linux/include/thrust/system/detail/sequential/merge.inl:19\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/cuda/bin/../targets/x86_64-linux/include/thrust/system/detail/sequential/merge.h:78\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/cuda/bin/../targets/x86_64-linux/include/thrust/system/cpp/detail/merge.h:22\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/cuda/bin/../targets/x86_64-linux/include/thrust/system/cpp/execution_policy.h:51\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/cuda/bin/../targets/x86_64-linux/include/thrust/execution_policy.h:32\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/cuda/bin/../targets/x86_64-linux/include/thrust/detail/get_iterator_value.h:20\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/cuda/bin/../targets/x86_64-linux/include/thrust/system/detail/generic/extrema.inl:25\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/cuda/bin/../targets/x86_64-linux/include/thrust/system/detail/generic/extrema.h:87\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/cuda/bin/../targets/x86_64-linux/include/thrust/detail/extrema.inl:22\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/cuda/bin/../targets/x86_64-linux/include/thrust/extrema.h:800\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Ksrc/cuda/cuda_kernel.cuh:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Ksrc/cuda/cuda_kernel.cu:1\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/cuda/bin/../targets/x86_64-linux/include/cub/util_cpp_dialect.cuh:142:13:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[KCUB requires at least C++14. C++11 is deprecated but still supported. C++11 support will be removed in a future release. Define CUB_IGNORE_DEPRECATED_CPP_DIALECT to suppress this message.\n",
            "  142 |      CUB_COM\u001b[01;35m\u001b[KPILER_DEPRECATION_SOFT(C++14, C++11);\u001b[m\u001b[K\n",
            "      |             \u001b[01;35m\u001b[K^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K                                                                                                                                                        \n",
            "In file included from \u001b[01m\u001b[K/usr/local/cuda/bin/../targets/x86_64-linux/include/thrust/detail/config/config.h:27\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/cuda/bin/../targets/x86_64-linux/include/thrust/detail/config.h:23\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/cuda/bin/../targets/x86_64-linux/include/thrust/extrema.h:23\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Ksrc/cuda/cuda_kernel.cuh:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Ksrc/cuda/cuda_kernel.cu:1\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/cuda/bin/../targets/x86_64-linux/include/thrust/detail/config/cpp_dialect.h:131:13:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[KThrust requires at least C++14. C++11 is deprecated but still supported. C++11 support will be removed in a future release. Define THRUST_IGNORE_DEPRECATED_CPP_DIALECT to suppress this message.\n",
            "  131 |      THRUST_\u001b[01;35m\u001b[KCOMPILER_DEPRECATION_SOFT(C++14, C++11);\u001b[m\u001b[K\n",
            "      |             \u001b[01;35m\u001b[K^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K                                                                                                                                                           \n",
            "In file included from \u001b[01m\u001b[K/usr/local/cuda/bin/../targets/x86_64-linux/include/cub/util_arch.cuh:36\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/cuda/bin/../targets/x86_64-linux/include/cub/detail/device_synchronize.cuh:20\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/cuda/bin/../targets/x86_64-linux/include/thrust/system/cuda/detail/util.h:36\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/cuda/bin/../targets/x86_64-linux/include/thrust/system/cuda/detail/for_each.h:35\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/cuda/bin/../targets/x86_64-linux/include/thrust/system/detail/adl/for_each.h:42\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/cuda/bin/../targets/x86_64-linux/include/thrust/detail/for_each.inl:27\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/cuda/bin/../targets/x86_64-linux/include/thrust/for_each.h:277\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/cuda/bin/../targets/x86_64-linux/include/thrust/system/detail/generic/transform.inl:19\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/cuda/bin/../targets/x86_64-linux/include/thrust/system/detail/generic/transform.h:104\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/cuda/bin/../targets/x86_64-linux/include/thrust/detail/transform.inl:27\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/cuda/bin/../targets/x86_64-linux/include/thrust/transform.h:721\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/cuda/bin/../targets/x86_64-linux/include/thrust/system/detail/generic/copy.inl:23\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/cuda/bin/../targets/x86_64-linux/include/thrust/system/detail/generic/copy.h:57\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/cuda/bin/../targets/x86_64-linux/include/thrust/detail/copy.inl:21\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/cuda/bin/../targets/x86_64-linux/include/thrust/detail/copy.h:90\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/cuda/bin/../targets/x86_64-linux/include/thrust/system/detail/sequential/merge.inl:19\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/cuda/bin/../targets/x86_64-linux/include/thrust/system/detail/sequential/merge.h:78\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/cuda/bin/../targets/x86_64-linux/include/thrust/system/cpp/detail/merge.h:22\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/cuda/bin/../targets/x86_64-linux/include/thrust/system/cpp/execution_policy.h:51\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/cuda/bin/../targets/x86_64-linux/include/thrust/execution_policy.h:32\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/cuda/bin/../targets/x86_64-linux/include/thrust/detail/get_iterator_value.h:20\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/cuda/bin/../targets/x86_64-linux/include/thrust/system/detail/generic/extrema.inl:25\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/cuda/bin/../targets/x86_64-linux/include/thrust/system/detail/generic/extrema.h:87\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/cuda/bin/../targets/x86_64-linux/include/thrust/detail/extrema.inl:22\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/cuda/bin/../targets/x86_64-linux/include/thrust/extrema.h:800\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Ksrc/cuda/cuda_kernel.cuh:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Ksrc/cuda/cuda_kernel.cu:1\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/cuda/bin/../targets/x86_64-linux/include/cub/util_cpp_dialect.cuh:142:13:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[KCUB requires at least C++14. C++11 is deprecated but still supported. C++11 support will be removed in a future release. Define CUB_IGNORE_DEPRECATED_CPP_DIALECT to suppress this message.\n",
            "  142 |      CUB_COM\u001b[01;35m\u001b[KPILER_DEPRECATION_SOFT(C++14, C++11);\u001b[m\u001b[K\n",
            "      |             \u001b[01;35m\u001b[K^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K                                                                                                                                                        \n",
            "nvcc -dc -O3 -std=c++11 -Isrc -Isrc/common -Isrc/seq -Isrc/cuda src/cuda/cuda_module.cu -o src/cuda/cuda_module.o\n",
            "In file included from \u001b[01m\u001b[K/usr/local/cuda/bin/../targets/x86_64-linux/include/thrust/detail/config/config.h:27\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/cuda/bin/../targets/x86_64-linux/include/thrust/detail/config.h:23\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/cuda/bin/../targets/x86_64-linux/include/thrust/extrema.h:23\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Ksrc/cuda/cuda_kernel.cuh:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Ksrc/cuda/cuda_module.cuh:5\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Ksrc/cuda/cuda_module.cu:1\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/cuda/bin/../targets/x86_64-linux/include/thrust/detail/config/cpp_dialect.h:131:13:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[KThrust requires at least C++14. C++11 is deprecated but still supported. C++11 support will be removed in a future release. Define THRUST_IGNORE_DEPRECATED_CPP_DIALECT to suppress this message.\n",
            "  131 |      THRUST_\u001b[01;35m\u001b[KCOMPILER_DEPRECATION_SOFT(C++14, C++11);\u001b[m\u001b[K\n",
            "      |             \u001b[01;35m\u001b[K^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K                                                                                                                                                           \n",
            "In file included from \u001b[01m\u001b[K/usr/local/cuda/bin/../targets/x86_64-linux/include/cub/util_arch.cuh:36\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/cuda/bin/../targets/x86_64-linux/include/cub/detail/device_synchronize.cuh:20\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/cuda/bin/../targets/x86_64-linux/include/thrust/system/cuda/detail/util.h:36\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/cuda/bin/../targets/x86_64-linux/include/thrust/system/cuda/detail/for_each.h:35\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/cuda/bin/../targets/x86_64-linux/include/thrust/system/detail/adl/for_each.h:42\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/cuda/bin/../targets/x86_64-linux/include/thrust/detail/for_each.inl:27\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/cuda/bin/../targets/x86_64-linux/include/thrust/for_each.h:277\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/cuda/bin/../targets/x86_64-linux/include/thrust/system/detail/generic/transform.inl:19\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/cuda/bin/../targets/x86_64-linux/include/thrust/system/detail/generic/transform.h:104\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/cuda/bin/../targets/x86_64-linux/include/thrust/detail/transform.inl:27\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/cuda/bin/../targets/x86_64-linux/include/thrust/transform.h:721\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/cuda/bin/../targets/x86_64-linux/include/thrust/system/detail/generic/copy.inl:23\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/cuda/bin/../targets/x86_64-linux/include/thrust/system/detail/generic/copy.h:57\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/cuda/bin/../targets/x86_64-linux/include/thrust/detail/copy.inl:21\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/cuda/bin/../targets/x86_64-linux/include/thrust/detail/copy.h:90\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/cuda/bin/../targets/x86_64-linux/include/thrust/system/detail/sequential/merge.inl:19\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/cuda/bin/../targets/x86_64-linux/include/thrust/system/detail/sequential/merge.h:78\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/cuda/bin/../targets/x86_64-linux/include/thrust/system/cpp/detail/merge.h:22\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/cuda/bin/../targets/x86_64-linux/include/thrust/system/cpp/execution_policy.h:51\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/cuda/bin/../targets/x86_64-linux/include/thrust/execution_policy.h:32\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/cuda/bin/../targets/x86_64-linux/include/thrust/detail/get_iterator_value.h:20\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/cuda/bin/../targets/x86_64-linux/include/thrust/system/detail/generic/extrema.inl:25\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/cuda/bin/../targets/x86_64-linux/include/thrust/system/detail/generic/extrema.h:87\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/cuda/bin/../targets/x86_64-linux/include/thrust/detail/extrema.inl:22\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/cuda/bin/../targets/x86_64-linux/include/thrust/extrema.h:800\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Ksrc/cuda/cuda_kernel.cuh:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Ksrc/cuda/cuda_module.cuh:5\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Ksrc/cuda/cuda_module.cu:1\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/cuda/bin/../targets/x86_64-linux/include/cub/util_cpp_dialect.cuh:142:13:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[KCUB requires at least C++14. C++11 is deprecated but still supported. C++11 support will be removed in a future release. Define CUB_IGNORE_DEPRECATED_CPP_DIALECT to suppress this message.\n",
            "  142 |      CUB_COM\u001b[01;35m\u001b[KPILER_DEPRECATION_SOFT(C++14, C++11);\u001b[m\u001b[K\n",
            "      |             \u001b[01;35m\u001b[K^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K                                                                                                                                                        \n",
            "In file included from \u001b[01m\u001b[K/usr/local/cuda/bin/../targets/x86_64-linux/include/thrust/detail/config/config.h:27\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/cuda/bin/../targets/x86_64-linux/include/thrust/detail/config.h:23\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/cuda/bin/../targets/x86_64-linux/include/thrust/extrema.h:23\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Ksrc/cuda/cuda_kernel.cuh:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Ksrc/cuda/cuda_module.cuh:5\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Ksrc/cuda/cuda_module.cu:1\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/cuda/bin/../targets/x86_64-linux/include/thrust/detail/config/cpp_dialect.h:131:13:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[KThrust requires at least C++14. C++11 is deprecated but still supported. C++11 support will be removed in a future release. Define THRUST_IGNORE_DEPRECATED_CPP_DIALECT to suppress this message.\n",
            "  131 |      THRUST_\u001b[01;35m\u001b[KCOMPILER_DEPRECATION_SOFT(C++14, C++11);\u001b[m\u001b[K\n",
            "      |             \u001b[01;35m\u001b[K^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K                                                                                                                                                           \n",
            "In file included from \u001b[01m\u001b[K/usr/local/cuda/bin/../targets/x86_64-linux/include/cub/util_arch.cuh:36\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/cuda/bin/../targets/x86_64-linux/include/cub/detail/device_synchronize.cuh:20\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/cuda/bin/../targets/x86_64-linux/include/thrust/system/cuda/detail/util.h:36\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/cuda/bin/../targets/x86_64-linux/include/thrust/system/cuda/detail/for_each.h:35\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/cuda/bin/../targets/x86_64-linux/include/thrust/system/detail/adl/for_each.h:42\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/cuda/bin/../targets/x86_64-linux/include/thrust/detail/for_each.inl:27\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/cuda/bin/../targets/x86_64-linux/include/thrust/for_each.h:277\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/cuda/bin/../targets/x86_64-linux/include/thrust/system/detail/generic/transform.inl:19\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/cuda/bin/../targets/x86_64-linux/include/thrust/system/detail/generic/transform.h:104\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/cuda/bin/../targets/x86_64-linux/include/thrust/detail/transform.inl:27\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/cuda/bin/../targets/x86_64-linux/include/thrust/transform.h:721\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/cuda/bin/../targets/x86_64-linux/include/thrust/system/detail/generic/copy.inl:23\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/cuda/bin/../targets/x86_64-linux/include/thrust/system/detail/generic/copy.h:57\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/cuda/bin/../targets/x86_64-linux/include/thrust/detail/copy.inl:21\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/cuda/bin/../targets/x86_64-linux/include/thrust/detail/copy.h:90\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/cuda/bin/../targets/x86_64-linux/include/thrust/system/detail/sequential/merge.inl:19\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/cuda/bin/../targets/x86_64-linux/include/thrust/system/detail/sequential/merge.h:78\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/cuda/bin/../targets/x86_64-linux/include/thrust/system/cpp/detail/merge.h:22\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/cuda/bin/../targets/x86_64-linux/include/thrust/system/cpp/execution_policy.h:51\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/cuda/bin/../targets/x86_64-linux/include/thrust/execution_policy.h:32\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/cuda/bin/../targets/x86_64-linux/include/thrust/detail/get_iterator_value.h:20\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/cuda/bin/../targets/x86_64-linux/include/thrust/system/detail/generic/extrema.inl:25\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/cuda/bin/../targets/x86_64-linux/include/thrust/system/detail/generic/extrema.h:87\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/cuda/bin/../targets/x86_64-linux/include/thrust/detail/extrema.inl:22\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/cuda/bin/../targets/x86_64-linux/include/thrust/extrema.h:800\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Ksrc/cuda/cuda_kernel.cuh:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Ksrc/cuda/cuda_module.cuh:5\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Ksrc/cuda/cuda_module.cu:1\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/cuda/bin/../targets/x86_64-linux/include/cub/util_cpp_dialect.cuh:142:13:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[KCUB requires at least C++14. C++11 is deprecated but still supported. C++11 support will be removed in a future release. Define CUB_IGNORE_DEPRECATED_CPP_DIALECT to suppress this message.\n",
            "  142 |      CUB_COM\u001b[01;35m\u001b[KPILER_DEPRECATION_SOFT(C++14, C++11);\u001b[m\u001b[K\n",
            "      |             \u001b[01;35m\u001b[K^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K                                                                                                                                                        \n",
            "nvcc -dc -O3 -std=c++11 -Isrc -Isrc/common -Isrc/seq -Isrc/cuda src/cuda/cuda_variable.cu -o src/cuda/cuda_variable.o\n",
            "In file included from \u001b[01m\u001b[K/usr/local/cuda/bin/../targets/x86_64-linux/include/thrust/detail/config/config.h:27\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/cuda/bin/../targets/x86_64-linux/include/thrust/detail/config.h:23\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/cuda/bin/../targets/x86_64-linux/include/thrust/extrema.h:23\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Ksrc/cuda/cuda_kernel.cuh:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Ksrc/cuda/cuda_variable.cuh:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Ksrc/cuda/cuda_variable.cu:1\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/cuda/bin/../targets/x86_64-linux/include/thrust/detail/config/cpp_dialect.h:131:13:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[KThrust requires at least C++14. C++11 is deprecated but still supported. C++11 support will be removed in a future release. Define THRUST_IGNORE_DEPRECATED_CPP_DIALECT to suppress this message.\n",
            "  131 |      THRUST_\u001b[01;35m\u001b[KCOMPILER_DEPRECATION_SOFT(C++14, C++11);\u001b[m\u001b[K\n",
            "      |             \u001b[01;35m\u001b[K^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K                                                                                                                                                           \n",
            "In file included from \u001b[01m\u001b[K/usr/local/cuda/bin/../targets/x86_64-linux/include/cub/util_arch.cuh:36\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/cuda/bin/../targets/x86_64-linux/include/cub/detail/device_synchronize.cuh:20\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/cuda/bin/../targets/x86_64-linux/include/thrust/system/cuda/detail/util.h:36\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/cuda/bin/../targets/x86_64-linux/include/thrust/system/cuda/detail/for_each.h:35\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/cuda/bin/../targets/x86_64-linux/include/thrust/system/detail/adl/for_each.h:42\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/cuda/bin/../targets/x86_64-linux/include/thrust/detail/for_each.inl:27\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/cuda/bin/../targets/x86_64-linux/include/thrust/for_each.h:277\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/cuda/bin/../targets/x86_64-linux/include/thrust/system/detail/generic/transform.inl:19\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/cuda/bin/../targets/x86_64-linux/include/thrust/system/detail/generic/transform.h:104\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/cuda/bin/../targets/x86_64-linux/include/thrust/detail/transform.inl:27\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/cuda/bin/../targets/x86_64-linux/include/thrust/transform.h:721\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/cuda/bin/../targets/x86_64-linux/include/thrust/system/detail/generic/copy.inl:23\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/cuda/bin/../targets/x86_64-linux/include/thrust/system/detail/generic/copy.h:57\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/cuda/bin/../targets/x86_64-linux/include/thrust/detail/copy.inl:21\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/cuda/bin/../targets/x86_64-linux/include/thrust/detail/copy.h:90\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/cuda/bin/../targets/x86_64-linux/include/thrust/system/detail/sequential/merge.inl:19\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/cuda/bin/../targets/x86_64-linux/include/thrust/system/detail/sequential/merge.h:78\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/cuda/bin/../targets/x86_64-linux/include/thrust/system/cpp/detail/merge.h:22\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/cuda/bin/../targets/x86_64-linux/include/thrust/system/cpp/execution_policy.h:51\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/cuda/bin/../targets/x86_64-linux/include/thrust/execution_policy.h:32\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/cuda/bin/../targets/x86_64-linux/include/thrust/detail/get_iterator_value.h:20\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/cuda/bin/../targets/x86_64-linux/include/thrust/system/detail/generic/extrema.inl:25\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/cuda/bin/../targets/x86_64-linux/include/thrust/system/detail/generic/extrema.h:87\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/cuda/bin/../targets/x86_64-linux/include/thrust/detail/extrema.inl:22\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/cuda/bin/../targets/x86_64-linux/include/thrust/extrema.h:800\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Ksrc/cuda/cuda_kernel.cuh:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Ksrc/cuda/cuda_variable.cuh:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Ksrc/cuda/cuda_variable.cu:1\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/cuda/bin/../targets/x86_64-linux/include/cub/util_cpp_dialect.cuh:142:13:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[KCUB requires at least C++14. C++11 is deprecated but still supported. C++11 support will be removed in a future release. Define CUB_IGNORE_DEPRECATED_CPP_DIALECT to suppress this message.\n",
            "  142 |      CUB_COM\u001b[01;35m\u001b[KPILER_DEPRECATION_SOFT(C++14, C++11);\u001b[m\u001b[K\n",
            "      |             \u001b[01;35m\u001b[K^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K                                                                                                                                                        \n",
            "In file included from \u001b[01m\u001b[K/usr/local/cuda/bin/../targets/x86_64-linux/include/thrust/detail/config/config.h:27\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/cuda/bin/../targets/x86_64-linux/include/thrust/detail/config.h:23\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/cuda/bin/../targets/x86_64-linux/include/thrust/extrema.h:23\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Ksrc/cuda/cuda_kernel.cuh:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Ksrc/cuda/cuda_variable.cuh:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Ksrc/cuda/cuda_variable.cu:1\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/cuda/bin/../targets/x86_64-linux/include/thrust/detail/config/cpp_dialect.h:131:13:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[KThrust requires at least C++14. C++11 is deprecated but still supported. C++11 support will be removed in a future release. Define THRUST_IGNORE_DEPRECATED_CPP_DIALECT to suppress this message.\n",
            "  131 |      THRUST_\u001b[01;35m\u001b[KCOMPILER_DEPRECATION_SOFT(C++14, C++11);\u001b[m\u001b[K\n",
            "      |             \u001b[01;35m\u001b[K^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K                                                                                                                                                           \n",
            "In file included from \u001b[01m\u001b[K/usr/local/cuda/bin/../targets/x86_64-linux/include/cub/util_arch.cuh:36\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/cuda/bin/../targets/x86_64-linux/include/cub/detail/device_synchronize.cuh:20\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/cuda/bin/../targets/x86_64-linux/include/thrust/system/cuda/detail/util.h:36\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/cuda/bin/../targets/x86_64-linux/include/thrust/system/cuda/detail/for_each.h:35\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/cuda/bin/../targets/x86_64-linux/include/thrust/system/detail/adl/for_each.h:42\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/cuda/bin/../targets/x86_64-linux/include/thrust/detail/for_each.inl:27\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/cuda/bin/../targets/x86_64-linux/include/thrust/for_each.h:277\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/cuda/bin/../targets/x86_64-linux/include/thrust/system/detail/generic/transform.inl:19\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/cuda/bin/../targets/x86_64-linux/include/thrust/system/detail/generic/transform.h:104\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/cuda/bin/../targets/x86_64-linux/include/thrust/detail/transform.inl:27\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/cuda/bin/../targets/x86_64-linux/include/thrust/transform.h:721\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/cuda/bin/../targets/x86_64-linux/include/thrust/system/detail/generic/copy.inl:23\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/cuda/bin/../targets/x86_64-linux/include/thrust/system/detail/generic/copy.h:57\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/cuda/bin/../targets/x86_64-linux/include/thrust/detail/copy.inl:21\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/cuda/bin/../targets/x86_64-linux/include/thrust/detail/copy.h:90\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/cuda/bin/../targets/x86_64-linux/include/thrust/system/detail/sequential/merge.inl:19\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/cuda/bin/../targets/x86_64-linux/include/thrust/system/detail/sequential/merge.h:78\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/cuda/bin/../targets/x86_64-linux/include/thrust/system/cpp/detail/merge.h:22\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/cuda/bin/../targets/x86_64-linux/include/thrust/system/cpp/execution_policy.h:51\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/cuda/bin/../targets/x86_64-linux/include/thrust/execution_policy.h:32\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/cuda/bin/../targets/x86_64-linux/include/thrust/detail/get_iterator_value.h:20\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/cuda/bin/../targets/x86_64-linux/include/thrust/system/detail/generic/extrema.inl:25\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/cuda/bin/../targets/x86_64-linux/include/thrust/system/detail/generic/extrema.h:87\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/cuda/bin/../targets/x86_64-linux/include/thrust/detail/extrema.inl:22\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/cuda/bin/../targets/x86_64-linux/include/thrust/extrema.h:800\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Ksrc/cuda/cuda_kernel.cuh:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Ksrc/cuda/cuda_variable.cuh:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Ksrc/cuda/cuda_variable.cu:1\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/cuda/bin/../targets/x86_64-linux/include/cub/util_cpp_dialect.cuh:142:13:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[KCUB requires at least C++14. C++11 is deprecated but still supported. C++11 support will be removed in a future release. Define CUB_IGNORE_DEPRECATED_CPP_DIALECT to suppress this message.\n",
            "  142 |      CUB_COM\u001b[01;35m\u001b[KPILER_DEPRECATION_SOFT(C++14, C++11);\u001b[m\u001b[K\n",
            "      |             \u001b[01;35m\u001b[K^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K                                                                                                                                                        \n",
            "nvcc -O3 -std=c++11 -Isrc -Isrc/common -Isrc/seq -Isrc/cuda src/cudamain.o src/common/parser.o src/common/timer.o src/seq/gcn.o src/seq/module.o src/seq/optim.o src/seq/rand.o src/seq/sparse.o src/seq/variable.o src/cuda/cuda_gcn.o src/cuda/cuda_kernel.o src/cuda/cuda_module.o src/cuda/cuda_variable.o -o cuda_gcn\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls\n",
        "!cd cuda_gcn && tar -xvzf data.tgz\n",
        "!ls\n",
        "! cd cuda_gcn && ./cuda_gcn cora"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JfkmSYHOE5yF",
        "outputId": "cd3dbffa-a99b-4b85-b426-bef43c96fcd0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda_gcn  sample_data\n",
            "data/citeseer.graph\n",
            "data/citeseer.split\n",
            "data/citeseer.svmlight\n",
            "data/cora.graph\n",
            "data/cora.split\n",
            "data/cora.svmlight\n",
            "data/pubmed.graph\n",
            "data/pubmed.split\n",
            "data/pubmed.svmlight\n",
            "cuda_gcn  sample_data\n",
            "Parse Graph Succeeded.\n",
            "Parse Node Succeeded.\n",
            "Parse Split Succeeded.\n",
            "RUNNING ON GPU\n",
            "epoch=1 train_loss=1.95446 train_acc=0.10000 val_loss=1.95084 val_acc=0.16200 time=0.00267\n",
            "epoch=2 train_loss=1.94993 train_acc=0.19286 val_loss=1.94780 val_acc=0.32200 time=0.00258\n",
            "epoch=3 train_loss=1.94513 train_acc=0.40714 val_loss=1.94508 val_acc=0.48400 time=0.00258\n",
            "epoch=4 train_loss=1.94124 train_acc=0.55000 val_loss=1.94227 val_acc=0.56200 time=0.00258\n",
            "epoch=5 train_loss=1.93738 train_acc=0.62143 val_loss=1.93919 val_acc=0.60200 time=0.00263\n",
            "epoch=6 train_loss=1.93077 train_acc=0.75714 val_loss=1.93611 val_acc=0.58800 time=0.00260\n",
            "epoch=7 train_loss=1.92629 train_acc=0.73571 val_loss=1.93315 val_acc=0.60200 time=0.00260\n",
            "epoch=8 train_loss=1.92252 train_acc=0.67143 val_loss=1.93016 val_acc=0.59800 time=0.00262\n",
            "epoch=9 train_loss=1.91770 train_acc=0.70000 val_loss=1.92730 val_acc=0.57400 time=0.00271\n",
            "epoch=10 train_loss=1.91522 train_acc=0.64286 val_loss=1.92449 val_acc=0.58600 time=0.00260\n",
            "epoch=11 train_loss=1.90459 train_acc=0.71429 val_loss=1.92175 val_acc=0.59600 time=0.00258\n",
            "epoch=12 train_loss=1.90348 train_acc=0.75000 val_loss=1.91895 val_acc=0.59800 time=0.00258\n",
            "epoch=13 train_loss=1.89464 train_acc=0.67857 val_loss=1.91600 val_acc=0.59600 time=0.00259\n",
            "epoch=14 train_loss=1.89332 train_acc=0.66429 val_loss=1.91305 val_acc=0.59800 time=0.00261\n",
            "epoch=15 train_loss=1.88849 train_acc=0.68571 val_loss=1.91016 val_acc=0.59800 time=0.00259\n",
            "epoch=16 train_loss=1.87669 train_acc=0.74286 val_loss=1.90728 val_acc=0.60600 time=0.00259\n",
            "epoch=17 train_loss=1.87737 train_acc=0.73571 val_loss=1.90449 val_acc=0.61000 time=0.00257\n",
            "epoch=18 train_loss=1.86779 train_acc=0.73571 val_loss=1.90175 val_acc=0.61600 time=0.00259\n",
            "epoch=19 train_loss=1.85440 train_acc=0.71429 val_loss=1.89897 val_acc=0.61200 time=0.00258\n",
            "epoch=20 train_loss=1.85888 train_acc=0.68571 val_loss=1.89617 val_acc=0.61000 time=0.00259\n",
            "epoch=21 train_loss=1.84861 train_acc=0.70000 val_loss=1.89334 val_acc=0.62000 time=0.00260\n",
            "epoch=22 train_loss=1.85175 train_acc=0.73571 val_loss=1.89041 val_acc=0.61800 time=0.00258\n",
            "epoch=23 train_loss=1.83218 train_acc=0.71429 val_loss=1.88730 val_acc=0.62600 time=0.00259\n",
            "epoch=24 train_loss=1.82066 train_acc=0.75000 val_loss=1.88415 val_acc=0.62400 time=0.00261\n",
            "epoch=25 train_loss=1.82544 train_acc=0.72857 val_loss=1.88096 val_acc=0.62200 time=0.00263\n",
            "epoch=26 train_loss=1.82974 train_acc=0.68571 val_loss=1.87776 val_acc=0.62000 time=0.00257\n",
            "epoch=27 train_loss=1.79554 train_acc=0.72857 val_loss=1.87443 val_acc=0.62400 time=0.00258\n",
            "epoch=28 train_loss=1.79831 train_acc=0.77857 val_loss=1.87112 val_acc=0.62200 time=0.00262\n",
            "epoch=29 train_loss=1.79618 train_acc=0.73571 val_loss=1.86777 val_acc=0.62800 time=0.00259\n",
            "epoch=30 train_loss=1.77867 train_acc=0.75714 val_loss=1.86422 val_acc=0.62800 time=0.00259\n",
            "epoch=31 train_loss=1.80467 train_acc=0.75714 val_loss=1.86054 val_acc=0.63200 time=0.00258\n",
            "epoch=32 train_loss=1.76875 train_acc=0.70000 val_loss=1.85664 val_acc=0.63400 time=0.00260\n",
            "epoch=33 train_loss=1.77656 train_acc=0.75714 val_loss=1.85266 val_acc=0.63800 time=0.00259\n",
            "epoch=34 train_loss=1.73172 train_acc=0.77857 val_loss=1.84867 val_acc=0.63600 time=0.00259\n",
            "epoch=35 train_loss=1.73343 train_acc=0.77143 val_loss=1.84448 val_acc=0.64200 time=0.00256\n",
            "epoch=36 train_loss=1.74998 train_acc=0.68571 val_loss=1.84037 val_acc=0.64600 time=0.00259\n",
            "epoch=37 train_loss=1.73255 train_acc=0.82143 val_loss=1.83634 val_acc=0.65600 time=0.00259\n",
            "epoch=38 train_loss=1.72369 train_acc=0.72857 val_loss=1.83225 val_acc=0.66000 time=0.00258\n",
            "epoch=39 train_loss=1.68501 train_acc=0.79286 val_loss=1.82812 val_acc=0.66000 time=0.00257\n",
            "epoch=40 train_loss=1.71114 train_acc=0.75714 val_loss=1.82402 val_acc=0.65600 time=0.00260\n",
            "epoch=41 train_loss=1.71855 train_acc=0.73571 val_loss=1.82013 val_acc=0.65800 time=0.00259\n",
            "epoch=42 train_loss=1.67787 train_acc=0.74286 val_loss=1.81637 val_acc=0.65000 time=0.00261\n",
            "epoch=43 train_loss=1.67905 train_acc=0.75714 val_loss=1.81247 val_acc=0.65000 time=0.00260\n",
            "epoch=44 train_loss=1.66013 train_acc=0.77857 val_loss=1.80846 val_acc=0.65400 time=0.00260\n",
            "epoch=45 train_loss=1.66230 train_acc=0.75000 val_loss=1.80418 val_acc=0.65000 time=0.00260\n",
            "epoch=46 train_loss=1.65725 train_acc=0.75000 val_loss=1.79967 val_acc=0.65400 time=0.00259\n",
            "epoch=47 train_loss=1.63505 train_acc=0.81429 val_loss=1.79515 val_acc=0.65600 time=0.00263\n",
            "epoch=48 train_loss=1.61435 train_acc=0.76429 val_loss=1.79044 val_acc=0.66800 time=0.00263\n",
            "epoch=49 train_loss=1.61128 train_acc=0.74286 val_loss=1.78550 val_acc=0.66400 time=0.00260\n",
            "epoch=50 train_loss=1.62166 train_acc=0.75714 val_loss=1.78054 val_acc=0.65800 time=0.00279\n",
            "epoch=51 train_loss=1.57268 train_acc=0.77857 val_loss=1.77575 val_acc=0.66000 time=0.00258\n",
            "epoch=52 train_loss=1.61464 train_acc=0.81429 val_loss=1.77088 val_acc=0.66400 time=0.00258\n",
            "epoch=53 train_loss=1.58032 train_acc=0.75000 val_loss=1.76604 val_acc=0.66000 time=0.00258\n",
            "epoch=54 train_loss=1.56032 train_acc=0.74286 val_loss=1.76137 val_acc=0.66200 time=0.00259\n",
            "epoch=55 train_loss=1.55188 train_acc=0.80714 val_loss=1.75672 val_acc=0.66400 time=0.00258\n",
            "epoch=56 train_loss=1.53553 train_acc=0.80000 val_loss=1.75218 val_acc=0.66400 time=0.00258\n",
            "epoch=57 train_loss=1.54535 train_acc=0.76429 val_loss=1.74763 val_acc=0.66600 time=0.00257\n",
            "epoch=58 train_loss=1.52388 train_acc=0.82143 val_loss=1.74306 val_acc=0.66200 time=0.00258\n",
            "epoch=59 train_loss=1.52150 train_acc=0.81429 val_loss=1.73860 val_acc=0.66000 time=0.00259\n",
            "epoch=60 train_loss=1.51683 train_acc=0.79286 val_loss=1.73423 val_acc=0.66000 time=0.00258\n",
            "epoch=61 train_loss=1.52831 train_acc=0.78571 val_loss=1.72977 val_acc=0.66000 time=0.00262\n",
            "epoch=62 train_loss=1.45717 train_acc=0.81429 val_loss=1.72537 val_acc=0.66000 time=0.00279\n",
            "epoch=63 train_loss=1.48407 train_acc=0.78571 val_loss=1.72115 val_acc=0.66200 time=0.00288\n",
            "epoch=64 train_loss=1.46211 train_acc=0.75000 val_loss=1.71718 val_acc=0.66000 time=0.00259\n",
            "epoch=65 train_loss=1.47445 train_acc=0.79286 val_loss=1.71314 val_acc=0.66000 time=0.00261\n",
            "epoch=66 train_loss=1.43947 train_acc=0.80000 val_loss=1.70896 val_acc=0.65600 time=0.00261\n",
            "epoch=67 train_loss=1.44215 train_acc=0.77857 val_loss=1.70480 val_acc=0.65800 time=0.00267\n",
            "epoch=68 train_loss=1.43933 train_acc=0.80714 val_loss=1.70056 val_acc=0.66200 time=0.00258\n",
            "epoch=69 train_loss=1.43901 train_acc=0.81429 val_loss=1.69654 val_acc=0.66200 time=0.00259\n",
            "epoch=70 train_loss=1.48427 train_acc=0.77857 val_loss=1.69254 val_acc=0.66400 time=0.00259\n",
            "epoch=71 train_loss=1.37527 train_acc=0.82857 val_loss=1.68834 val_acc=0.66600 time=0.00257\n",
            "epoch=72 train_loss=1.40153 train_acc=0.79286 val_loss=1.68401 val_acc=0.66800 time=0.00258\n",
            "epoch=73 train_loss=1.39319 train_acc=0.79286 val_loss=1.67961 val_acc=0.67200 time=0.00256\n",
            "epoch=74 train_loss=1.39043 train_acc=0.82143 val_loss=1.67501 val_acc=0.67600 time=0.00262\n",
            "epoch=75 train_loss=1.39406 train_acc=0.79286 val_loss=1.67010 val_acc=0.68000 time=0.00269\n",
            "epoch=76 train_loss=1.34550 train_acc=0.81429 val_loss=1.66505 val_acc=0.68000 time=0.00360\n",
            "epoch=77 train_loss=1.37068 train_acc=0.81429 val_loss=1.65960 val_acc=0.68000 time=0.00267\n",
            "epoch=78 train_loss=1.39180 train_acc=0.77857 val_loss=1.65445 val_acc=0.68200 time=0.00266\n",
            "epoch=79 train_loss=1.34988 train_acc=0.80714 val_loss=1.64931 val_acc=0.68600 time=0.00266\n",
            "epoch=80 train_loss=1.33447 train_acc=0.82143 val_loss=1.64431 val_acc=0.68800 time=0.00263\n",
            "epoch=81 train_loss=1.34448 train_acc=0.84286 val_loss=1.63938 val_acc=0.68800 time=0.00258\n",
            "epoch=82 train_loss=1.32454 train_acc=0.85714 val_loss=1.63464 val_acc=0.69000 time=0.00256\n",
            "epoch=83 train_loss=1.32228 train_acc=0.81429 val_loss=1.63018 val_acc=0.69200 time=0.00256\n",
            "epoch=84 train_loss=1.35930 train_acc=0.82143 val_loss=1.62586 val_acc=0.69400 time=0.00257\n",
            "epoch=85 train_loss=1.32936 train_acc=0.83571 val_loss=1.62149 val_acc=0.69800 time=0.00264\n",
            "epoch=86 train_loss=1.29925 train_acc=0.80000 val_loss=1.61738 val_acc=0.70000 time=0.00371\n",
            "epoch=87 train_loss=1.32273 train_acc=0.85000 val_loss=1.61339 val_acc=0.70000 time=0.00271\n",
            "epoch=88 train_loss=1.27435 train_acc=0.82143 val_loss=1.60957 val_acc=0.70200 time=0.00262\n",
            "epoch=89 train_loss=1.31170 train_acc=0.83571 val_loss=1.60609 val_acc=0.70400 time=0.00175\n",
            "epoch=90 train_loss=1.29039 train_acc=0.85000 val_loss=1.60247 val_acc=0.70600 time=0.00155\n",
            "epoch=91 train_loss=1.25323 train_acc=0.86429 val_loss=1.59873 val_acc=0.70600 time=0.00156\n",
            "epoch=92 train_loss=1.21819 train_acc=0.85714 val_loss=1.59527 val_acc=0.70000 time=0.00156\n",
            "epoch=93 train_loss=1.23154 train_acc=0.83571 val_loss=1.59174 val_acc=0.69800 time=0.00151\n",
            "epoch=94 train_loss=1.18311 train_acc=0.85714 val_loss=1.58778 val_acc=0.69800 time=0.00151\n",
            "epoch=95 train_loss=1.23211 train_acc=0.86429 val_loss=1.58327 val_acc=0.70200 time=0.00152\n",
            "epoch=96 train_loss=1.19378 train_acc=0.86429 val_loss=1.57844 val_acc=0.70200 time=0.00151\n",
            "epoch=97 train_loss=1.18224 train_acc=0.85714 val_loss=1.57370 val_acc=0.70200 time=0.00150\n",
            "epoch=98 train_loss=1.19661 train_acc=0.87143 val_loss=1.56855 val_acc=0.70600 time=0.00150\n",
            "epoch=99 train_loss=1.25985 train_acc=0.85714 val_loss=1.56322 val_acc=0.71400 time=0.00153\n",
            "epoch=100 train_loss=1.14922 train_acc=0.87143 val_loss=1.55801 val_acc=0.71600 time=0.00151\n",
            "total training time=0.25014\n",
            "test_loss=1.54386 test_acc=0.73900 time=0.00045\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# author: chinhua\n",
        "#https://blog.csdn.net/zzc_zhuyu/article/details/89929129\n",
        "# 利用硬件实现矩阵乘法加速\n",
        "#矩陣鏈乘法（或矩陣鏈排序問題[1]）是關於以最有效的方式乘以給定矩陣序列的優化問題。問題實際上不是執行乘法，而只是決定所涉及的矩陣乘法的順序。該問題可以使用動態規劃來解決。\n",
        "%%writefile ./cuda_gcn/src/cuda/cuda_kernel.cu\n",
        "\n",
        "#include \"cuda_kernel.cuh\"\n",
        "\n",
        "curandState *devStates;\n",
        "\n",
        "\n",
        "__global__ void cuda_Matmul_forward_kernel(const float *a, const float *b, float *c, const uint m, const uint n, const uint p) {\n",
        "    __shared__ float tileA[TILE_SIZE][TILE_SIZE];\n",
        "    __shared__ float tileB[TILE_SIZE][TILE_SIZE];\n",
        "    int bx = blockIdx.x, by = blockIdx.y, tx = threadIdx.x, ty = threadIdx.y;\n",
        "    int row = by * TILE_SIZE + ty;\n",
        "    int col = bx * TILE_SIZE + tx;\n",
        "\n",
        "    // Initialize partial result\n",
        "    float res_kij = 0;\n",
        "\n",
        "    for (int k = 0; k < (n-1) / TILE_SIZE + 1; ++k) {\n",
        "        // Load tileA\n",
        "        if (row < m && k * TILE_SIZE + tx < n)\n",
        "            tileA[ty][tx] = a[row * n + k * TILE_SIZE + tx];\n",
        "        else\n",
        "            tileA[ty][tx] = 0;\n",
        "\n",
        "        // Load tileB\n",
        "        if (col < p && k * TILE_SIZE + ty < n)\n",
        "            tileB[ty][tx] = b[(k * TILE_SIZE + ty) * p + col];\n",
        "        else\n",
        "            tileB[ty][tx] = 0;\n",
        "\n",
        "        __syncthreads();\n",
        "\n",
        "        // Compute partial result for each tile\n",
        "        for (int i = 0; i < TILE_SIZE; ++i) {\n",
        "            if (row < m && col < p)\n",
        "                res_kij += tileA[ty][i] * tileB[i][tx];\n",
        "        }\n",
        "\n",
        "        __syncthreads();\n",
        "    }\n",
        "\n",
        "    // Store the final result\n",
        "    if (row < m && col < p)\n",
        "        c[row * p + col] = res_kij;\n",
        "}\n",
        "\n",
        "\n",
        "__global__\n",
        "void cuda_Matmul_backward_A_kernel(float *a_grad, const float *b, const float *c_grad, const uint m, const uint n, const uint p) {\n",
        "    __shared__ float tileB[TILE_SIZE][TILE_SIZE];\n",
        "    __shared__ float tileCGrad[TILE_SIZE][TILE_SIZE];\n",
        "    int bx = blockIdx.x, by = blockIdx.y, tx = threadIdx.x, ty = threadIdx.y;\n",
        "    int row = by * TILE_SIZE + ty;\n",
        "    int col = bx * TILE_SIZE + tx;\n",
        "    int range = (p-1) / TILE_SIZE + 1;\n",
        "    float res = 0;\n",
        "    #pragma unroll\n",
        "    for (int i = 0; i < range; i++) {\n",
        "        if (row < m && i * TILE_SIZE + tx < p)\n",
        "            tileCGrad[ty][tx] = c_grad[row * p + i * TILE_SIZE + tx];\n",
        "        else\n",
        "            tileCGrad[ty][tx] = 0;\n",
        "        if (col < n && i * TILE_SIZE + ty < p)\n",
        "            tileB[ty][tx] = b[col * p + i * TILE_SIZE + ty];\n",
        "        else\n",
        "            tileB[ty][tx] = 0;\n",
        "        __syncthreads();\n",
        "\n",
        "        #pragma unroll\n",
        "        for (int j = 0; j < TILE_SIZE; j++)\n",
        "            res += tileCGrad[ty][j] * tileB[j][tx];\n",
        "        __syncthreads();\n",
        "    }\n",
        "    if (row < m && col < n)\n",
        "        a_grad[row * n + col] = res;\n",
        "}\n",
        "\n",
        "__global__\n",
        "void cuda_Matmul_backward_B_kernel(float *b_grad, const float *a, const float *c_grad, const uint m, const uint n, const uint p) {\n",
        "    __shared__ float tileA[TILE_SIZE][TILE_SIZE];\n",
        "    __shared__ float tileCGrad[TILE_SIZE][TILE_SIZE];\n",
        "    int bx = blockIdx.x, by = blockIdx.y, tx = threadIdx.x, ty = threadIdx.y;\n",
        "    int row = by * TILE_SIZE + ty;\n",
        "    int col = bx * TILE_SIZE + tx;\n",
        "    int range = (m-1)/TILE_SIZE+1;\n",
        "    float res = 0;\n",
        "\n",
        "    #pragma unroll\n",
        "    for (int i = 0; i < range; i++) {\n",
        "        if (row < n && i * TILE_SIZE + tx < m)\n",
        "            tileA[ty][tx] = a[(i * TILE_SIZE + tx) * n + row];\n",
        "        else\n",
        "            tileA[ty][tx] = 0;\n",
        "        if (col < p && i * TILE_SIZE + ty < m)\n",
        "            tileCGrad[ty][tx] = c_grad[(i * TILE_SIZE + ty) * p + col];\n",
        "        else\n",
        "            tileCGrad[ty][tx] = 0;\n",
        "        __syncthreads();\n",
        "\n",
        "        #pragma unroll\n",
        "        for (int j = 0; j < TILE_SIZE; j++)\n",
        "            res += tileA[ty][j] * tileCGrad[j][tx];\n",
        "        __syncthreads();\n",
        "    }\n",
        "    if (row < n && col < p)\n",
        "        b_grad[row * p + col] = res;\n",
        "}\n",
        "\n",
        "\n",
        "// sparse matmul\n",
        "__global__\n",
        "void cuda_SparseMatmul_forward_kernel(float *a_in, float *b_in, float *c_in, int *indptr, int *indices, int p) {\n",
        "    int i = blockIdx.x;\n",
        "    int k = threadIdx.x;\n",
        "\n",
        "    #pragma unroll\n",
        "    for (int jj = indptr[i]; jj < indptr[i + 1]; jj++) {\n",
        "        int j = indices[jj];\n",
        "        c_in[i * p + k] += a_in[jj] * b_in[j * p + k];\n",
        "    }\n",
        "}\n",
        "\n",
        "__global__\n",
        "void cuda_SparseMatmul_backward_kernel(float *a_in, float *b_in, float *c_in, int *indptr, int *indices, int p) {\n",
        "    int i = blockIdx.x;\n",
        "    int k = threadIdx.x;\n",
        "\n",
        "    #pragma unroll\n",
        "    for (int jj = indptr[i]; jj < indptr[i + 1]; jj++){\n",
        "        int j = indices[jj];\n",
        "        b_in[j * p + k] += c_in[i * p + k] * a_in[jj];\n",
        "    }\n",
        "}\n",
        "\n",
        "\n",
        "// graph sum\n",
        "__global__\n",
        "void cuda_GraphSum_forward_kernel(float *d_in_data, float *d_out_data, int *d_indptr, int *d_indices, int dim, int numNodes) {\n",
        "    int src = blockIdx.x;\n",
        "    int j = threadIdx.x;\n",
        "\n",
        "    int ptr_src_0 = d_indptr[src];\n",
        "    int ptr_stc_1 = d_indptr[src + 1];\n",
        "\n",
        "    #pragma unroll\n",
        "    for (int i = ptr_src_0; i < ptr_stc_1; i++) {\n",
        "        int dst = d_indices[i];\n",
        "        float coef = 1.0 / sqrtf(\n",
        "                (ptr_stc_1 - ptr_src_0) * (d_indptr[dst + 1] - d_indptr[dst])\n",
        "        );\n",
        "        // This only works for undirected graphs. Should be out[dst] += coef * in[src]]\n",
        "        d_out_data[src * dim + j] += coef * d_in_data[dst * dim + j];\n",
        "    }\n",
        "}\n",
        "\n",
        "__global__\n",
        "void cuda_GraphSum_backward_kernel(float *d_in_grad, float *d_out_grad, int *d_indptr, int *d_indices, int dim, int numNodes) {\n",
        "    int src = blockIdx.x;\n",
        "    int j = threadIdx.x;\n",
        "\n",
        "    int ptr_src_0 = d_indptr[src];\n",
        "    int ptr_stc_1 = d_indptr[src + 1];\n",
        "\n",
        "    #pragma unroll\n",
        "    for (int i = ptr_src_0; i < ptr_stc_1; i++) {\n",
        "        int dst = d_indices[i];\n",
        "        float coef = 1.0 / sqrtf(\n",
        "                (ptr_stc_1 - ptr_src_0) * (d_indptr[dst + 1] - d_indptr[dst])\n",
        "        );\n",
        "        // This only works for undirected graphs. Should be out[dst] += coef * in[src]\n",
        "        d_in_grad[src * dim + j] += coef * d_out_grad[dst * dim + j];\n",
        "    }\n",
        "}\n",
        "\n",
        "\n",
        "// cross entropy\n",
        "__global__\n",
        "void cuda_CrossEntropy_forward_A_kernel(float* logits_data, float* logits_grad, bool training, int num_classes, int* truth, int* count, float* thread_loss, int size) {\n",
        "    int i = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "    if (i >= size) return;\n",
        "    if (truth[i] < 0) {\n",
        "        count[i] = 0;\n",
        "        return;\n",
        "    }\n",
        "    float *logit = &logits_data[i * num_classes];\n",
        "    float max_logit = -1e30, sum_exp = 0;\n",
        "    #pragma unroll\n",
        "    for (int j = 0; j < num_classes; j++)\n",
        "        max_logit = fmax(max_logit, logit[j]);\n",
        "    #pragma unroll\n",
        "    for (int j = 0; j < num_classes; j++) {\n",
        "        logit[j] -= max_logit;\n",
        "        sum_exp += expf(logit[j]);\n",
        "    }\n",
        "    if (training) {\n",
        "        #pragma unroll\n",
        "        for (int j = 0; j < num_classes; j++) {\n",
        "            float prob = expf(logit[j]) / sum_exp;\n",
        "            logits_grad[i * num_classes + j] = prob;\n",
        "        }\n",
        "        logits_grad[i * num_classes + truth[i]] -= 1.0;\n",
        "    }\n",
        "    count[i] = 1;\n",
        "    thread_loss[i] = logf(sum_exp) - logit[truth[i]];\n",
        "}\n",
        "\n",
        "__global__\n",
        "void cuda_CrossEntropy_forward_B_kernel(float *logits_grad, int size, int count) {\n",
        "    int i = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "    if (i < size) logits_grad[i] /= count;\n",
        "}\n",
        "\n",
        "\n",
        "// ReLU\n",
        "__global__\n",
        "void cuda_ReLU_forward_kernel(float *d_in_data, bool *d_mask, const long unsigned int datasize, bool training) {\n",
        "    uint i = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "    if (i >= datasize) return;\n",
        "\n",
        "    bool keep = d_in_data[i] > 0;\n",
        "    if (training) d_mask[i] = keep;\n",
        "    if (!keep) d_in_data[i] = 0;\n",
        "}\n",
        "\n",
        "__global__\n",
        "void cuda_ReLU_backward_kernel(float *d_in_grad, bool *d_mask, long unsigned int datasize) {\n",
        "    uint i = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "    if (i >= datasize) return;\n",
        "    if (!d_mask[i]) d_in_grad[i] = 0;\n",
        "}\n",
        "\n",
        "\n",
        "// Dropout\n",
        "__global__\n",
        "void cuda_Dropout_forward_kernel(float *in, int *mask, curandState *state, const uint size, const float p, const float scale, const bool useMask) {\n",
        "    float x;\n",
        "    bool keep;\n",
        "    int id = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "    if (id < size) {\n",
        "        x = curand_uniform(&state[id % MAX_THREAD_PER_BLOCK]);\n",
        "        keep = x >= p;\n",
        "        in[id] *= keep ? scale : 0;\n",
        "        if (useMask) mask[id] = keep;\n",
        "    }\n",
        "}\n",
        "\n",
        "__global__\n",
        "void cuda_Dropout_backward_kernel(float *in_grad, const int *mask, const uint size, const float scale) {\n",
        "    int id = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "    if (id < size) in_grad[id] *= mask[id] ? scale : 0;\n",
        "}\n",
        "\n",
        "\n",
        "// rand state\n",
        "__global__\n",
        "void cuda_init_rand_kernel(curandState *state) {\n",
        "    int id = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "    curand_init(1234, id, 0, &state[id]);\n",
        "}\n",
        "\n",
        "void cuda_init_random_state(const uint size) {\n",
        "    // malloc\n",
        "    CUDA_CHECK(cudaMalloc((void**) &devStates, size * sizeof(curandState)));\n",
        "\n",
        "    dim3 block((size-1)/MAX_THREAD_PER_BLOCK + 1, 1, 1);\n",
        "    dim3 thread_in_block(MAX_THREAD_PER_BLOCK, 1, 1);\n",
        "\n",
        "    // kernel\n",
        "    cuda_init_rand_kernel<<<block,thread_in_block>>>(devStates);\n",
        "    CUDA_CHECK(cudaGetLastError());\n",
        "    // CUDA_CHECK(cudaDeviceSynchronize());\n",
        "}\n",
        "\n",
        "void cuda_free_random_state() {\n",
        "    // free\n",
        "    CUDA_CHECK(cudaFree(devStates));\n",
        "}\n",
        "\n",
        "\n",
        "// adam\n",
        "__global__\n",
        "void cuda_Adam_step_kernel(float* grad, float* data, float* m, float* v, bool decay, float weight_decay, float beta1, float beta2, float eps, float step_size, int varsize) {\n",
        "    int i = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "\n",
        "    if (i >= varsize) return;\n",
        "\n",
        "    float g = grad[i];\n",
        "    if (decay) g += weight_decay * data[i];\n",
        "    m[i] = beta1 * m[i] + (1.0 - beta1) * g;\n",
        "    v[i] = beta2 * v[i] + (1.0 - beta2) * g * g;\n",
        "    data[i] -= step_size * m[i] / (sqrtf(v[i]) + eps);\n",
        "}\n",
        "\n",
        "__global__\n",
        "void cuda_set_truth_kernel(int *truth, int *data_split, int *data_label, int current_split, int size) {\n",
        "    int id = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "    if (id < size)\n",
        "        truth[id] = data_split[id] == current_split ? data_label[id] : -1;\n",
        "}\n",
        "\n",
        "__global__\n",
        "void cuda_Variable_glorot_kernel(float *data, curandState *state, int size, float scale) {\n",
        "    int id = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "    if (id < size)\n",
        "        data[id] = (curand_uniform(&state[id % MAX_THREAD_PER_BLOCK]) - 0.5) * scale;\n",
        "}\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zXTb8LCvYnfM",
        "outputId": "6da9a1cf-d2b8-44b2-cd02-eb713c233938"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting ./cuda_gcn/src/cuda/cuda_kernel.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! cd cuda_gcn && make cuda"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TuHg4rXydVs2",
        "outputId": "69d94d5f-edd8-41ca-be5c-88a0bb7af393"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nvcc -dc -O3 -std=c++11 -Isrc -Isrc/common -Isrc/seq -Isrc/cuda src/cuda/cuda_kernel.cu -o src/cuda/cuda_kernel.o\n",
            "In file included from \u001b[01m\u001b[K/usr/local/cuda/bin/../targets/x86_64-linux/include/thrust/detail/config/config.h:27\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/cuda/bin/../targets/x86_64-linux/include/thrust/detail/config.h:23\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/cuda/bin/../targets/x86_64-linux/include/thrust/extrema.h:23\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Ksrc/cuda/cuda_kernel.cuh:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Ksrc/cuda/cuda_kernel.cu:2\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/cuda/bin/../targets/x86_64-linux/include/thrust/detail/config/cpp_dialect.h:131:13:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[KThrust requires at least C++14. C++11 is deprecated but still supported. C++11 support will be removed in a future release. Define THRUST_IGNORE_DEPRECATED_CPP_DIALECT to suppress this message.\n",
            "  131 |      THRUST_\u001b[01;35m\u001b[KCOMPILER_DEPRECATION_SOFT(C++14, C++11);\u001b[m\u001b[K\n",
            "      |             \u001b[01;35m\u001b[K^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K                                                                                                                                                           \n",
            "In file included from \u001b[01m\u001b[K/usr/local/cuda/bin/../targets/x86_64-linux/include/cub/util_arch.cuh:36\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/cuda/bin/../targets/x86_64-linux/include/cub/detail/device_synchronize.cuh:20\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/cuda/bin/../targets/x86_64-linux/include/thrust/system/cuda/detail/util.h:36\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/cuda/bin/../targets/x86_64-linux/include/thrust/system/cuda/detail/for_each.h:35\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/cuda/bin/../targets/x86_64-linux/include/thrust/system/detail/adl/for_each.h:42\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/cuda/bin/../targets/x86_64-linux/include/thrust/detail/for_each.inl:27\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/cuda/bin/../targets/x86_64-linux/include/thrust/for_each.h:277\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/cuda/bin/../targets/x86_64-linux/include/thrust/system/detail/generic/transform.inl:19\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/cuda/bin/../targets/x86_64-linux/include/thrust/system/detail/generic/transform.h:104\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/cuda/bin/../targets/x86_64-linux/include/thrust/detail/transform.inl:27\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/cuda/bin/../targets/x86_64-linux/include/thrust/transform.h:721\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/cuda/bin/../targets/x86_64-linux/include/thrust/system/detail/generic/copy.inl:23\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/cuda/bin/../targets/x86_64-linux/include/thrust/system/detail/generic/copy.h:57\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/cuda/bin/../targets/x86_64-linux/include/thrust/detail/copy.inl:21\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/cuda/bin/../targets/x86_64-linux/include/thrust/detail/copy.h:90\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/cuda/bin/../targets/x86_64-linux/include/thrust/system/detail/sequential/merge.inl:19\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/cuda/bin/../targets/x86_64-linux/include/thrust/system/detail/sequential/merge.h:78\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/cuda/bin/../targets/x86_64-linux/include/thrust/system/cpp/detail/merge.h:22\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/cuda/bin/../targets/x86_64-linux/include/thrust/system/cpp/execution_policy.h:51\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/cuda/bin/../targets/x86_64-linux/include/thrust/execution_policy.h:32\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/cuda/bin/../targets/x86_64-linux/include/thrust/detail/get_iterator_value.h:20\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/cuda/bin/../targets/x86_64-linux/include/thrust/system/detail/generic/extrema.inl:25\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/cuda/bin/../targets/x86_64-linux/include/thrust/system/detail/generic/extrema.h:87\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/cuda/bin/../targets/x86_64-linux/include/thrust/detail/extrema.inl:22\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/cuda/bin/../targets/x86_64-linux/include/thrust/extrema.h:800\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Ksrc/cuda/cuda_kernel.cuh:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Ksrc/cuda/cuda_kernel.cu:2\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/cuda/bin/../targets/x86_64-linux/include/cub/util_cpp_dialect.cuh:142:13:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[KCUB requires at least C++14. C++11 is deprecated but still supported. C++11 support will be removed in a future release. Define CUB_IGNORE_DEPRECATED_CPP_DIALECT to suppress this message.\n",
            "  142 |      CUB_COM\u001b[01;35m\u001b[KPILER_DEPRECATION_SOFT(C++14, C++11);\u001b[m\u001b[K\n",
            "      |             \u001b[01;35m\u001b[K^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K                                                                                                                                                        \n",
            "In file included from \u001b[01m\u001b[K/usr/local/cuda/bin/../targets/x86_64-linux/include/thrust/detail/config/config.h:27\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/cuda/bin/../targets/x86_64-linux/include/thrust/detail/config.h:23\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/cuda/bin/../targets/x86_64-linux/include/thrust/extrema.h:23\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Ksrc/cuda/cuda_kernel.cuh:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Ksrc/cuda/cuda_kernel.cu:2\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/cuda/bin/../targets/x86_64-linux/include/thrust/detail/config/cpp_dialect.h:131:13:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[KThrust requires at least C++14. C++11 is deprecated but still supported. C++11 support will be removed in a future release. Define THRUST_IGNORE_DEPRECATED_CPP_DIALECT to suppress this message.\n",
            "  131 |      THRUST_\u001b[01;35m\u001b[KCOMPILER_DEPRECATION_SOFT(C++14, C++11);\u001b[m\u001b[K\n",
            "      |             \u001b[01;35m\u001b[K^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K                                                                                                                                                           \n",
            "In file included from \u001b[01m\u001b[K/usr/local/cuda/bin/../targets/x86_64-linux/include/cub/util_arch.cuh:36\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/cuda/bin/../targets/x86_64-linux/include/cub/detail/device_synchronize.cuh:20\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/cuda/bin/../targets/x86_64-linux/include/thrust/system/cuda/detail/util.h:36\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/cuda/bin/../targets/x86_64-linux/include/thrust/system/cuda/detail/for_each.h:35\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/cuda/bin/../targets/x86_64-linux/include/thrust/system/detail/adl/for_each.h:42\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/cuda/bin/../targets/x86_64-linux/include/thrust/detail/for_each.inl:27\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/cuda/bin/../targets/x86_64-linux/include/thrust/for_each.h:277\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/cuda/bin/../targets/x86_64-linux/include/thrust/system/detail/generic/transform.inl:19\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/cuda/bin/../targets/x86_64-linux/include/thrust/system/detail/generic/transform.h:104\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/cuda/bin/../targets/x86_64-linux/include/thrust/detail/transform.inl:27\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/cuda/bin/../targets/x86_64-linux/include/thrust/transform.h:721\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/cuda/bin/../targets/x86_64-linux/include/thrust/system/detail/generic/copy.inl:23\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/cuda/bin/../targets/x86_64-linux/include/thrust/system/detail/generic/copy.h:57\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/cuda/bin/../targets/x86_64-linux/include/thrust/detail/copy.inl:21\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/cuda/bin/../targets/x86_64-linux/include/thrust/detail/copy.h:90\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/cuda/bin/../targets/x86_64-linux/include/thrust/system/detail/sequential/merge.inl:19\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/cuda/bin/../targets/x86_64-linux/include/thrust/system/detail/sequential/merge.h:78\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/cuda/bin/../targets/x86_64-linux/include/thrust/system/cpp/detail/merge.h:22\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/cuda/bin/../targets/x86_64-linux/include/thrust/system/cpp/execution_policy.h:51\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/cuda/bin/../targets/x86_64-linux/include/thrust/execution_policy.h:32\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/cuda/bin/../targets/x86_64-linux/include/thrust/detail/get_iterator_value.h:20\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/cuda/bin/../targets/x86_64-linux/include/thrust/system/detail/generic/extrema.inl:25\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/cuda/bin/../targets/x86_64-linux/include/thrust/system/detail/generic/extrema.h:87\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/cuda/bin/../targets/x86_64-linux/include/thrust/detail/extrema.inl:22\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/cuda/bin/../targets/x86_64-linux/include/thrust/extrema.h:800\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Ksrc/cuda/cuda_kernel.cuh:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Ksrc/cuda/cuda_kernel.cu:2\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/cuda/bin/../targets/x86_64-linux/include/cub/util_cpp_dialect.cuh:142:13:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[KCUB requires at least C++14. C++11 is deprecated but still supported. C++11 support will be removed in a future release. Define CUB_IGNORE_DEPRECATED_CPP_DIALECT to suppress this message.\n",
            "  142 |      CUB_COM\u001b[01;35m\u001b[KPILER_DEPRECATION_SOFT(C++14, C++11);\u001b[m\u001b[K\n",
            "      |             \u001b[01;35m\u001b[K^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K                                                                                                                                                        \n",
            "nvcc -O3 -std=c++11 -Isrc -Isrc/common -Isrc/seq -Isrc/cuda src/cudamain.o src/common/parser.o src/common/timer.o src/seq/gcn.o src/seq/module.o src/seq/optim.o src/seq/rand.o src/seq/sparse.o src/seq/variable.o src/cuda/cuda_gcn.o src/cuda/cuda_kernel.o src/cuda/cuda_module.o src/cuda/cuda_variable.o -o cuda_gcn\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! cd cuda_gcn && ./cuda_gcn cora"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0g0MNAcFJno1",
        "outputId": "9c69ad55-278b-4c69-ae2a-af244a8b3e94"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Parse Graph Succeeded.\n",
            "Parse Node Succeeded.\n",
            "Parse Split Succeeded.\n",
            "RUNNING ON GPU\n",
            "epoch=1 train_loss=1.95437 train_acc=0.12143 val_loss=1.95068 val_acc=0.19600 time=0.00267\n",
            "epoch=2 train_loss=1.94982 train_acc=0.20714 val_loss=1.94763 val_acc=0.35000 time=0.00259\n",
            "epoch=3 train_loss=1.94468 train_acc=0.44286 val_loss=1.94493 val_acc=0.48600 time=0.00261\n",
            "epoch=4 train_loss=1.94036 train_acc=0.57857 val_loss=1.94223 val_acc=0.55400 time=0.00258\n",
            "epoch=5 train_loss=1.93771 train_acc=0.59286 val_loss=1.93932 val_acc=0.59200 time=0.00263\n",
            "epoch=6 train_loss=1.93042 train_acc=0.70714 val_loss=1.93614 val_acc=0.61000 time=0.00259\n",
            "epoch=7 train_loss=1.92593 train_acc=0.72857 val_loss=1.93298 val_acc=0.60200 time=0.00260\n",
            "epoch=8 train_loss=1.92111 train_acc=0.67857 val_loss=1.92991 val_acc=0.58400 time=0.00258\n",
            "epoch=9 train_loss=1.91765 train_acc=0.70714 val_loss=1.92688 val_acc=0.58800 time=0.00260\n",
            "epoch=10 train_loss=1.91529 train_acc=0.65714 val_loss=1.92385 val_acc=0.59400 time=0.00260\n",
            "epoch=11 train_loss=1.90228 train_acc=0.70714 val_loss=1.92090 val_acc=0.59400 time=0.00258\n",
            "epoch=12 train_loss=1.90149 train_acc=0.77857 val_loss=1.91800 val_acc=0.59800 time=0.00258\n",
            "epoch=13 train_loss=1.89649 train_acc=0.65714 val_loss=1.91515 val_acc=0.59000 time=0.00257\n",
            "epoch=14 train_loss=1.89592 train_acc=0.67857 val_loss=1.91227 val_acc=0.59000 time=0.00260\n",
            "epoch=15 train_loss=1.88669 train_acc=0.68571 val_loss=1.90944 val_acc=0.59000 time=0.00262\n",
            "epoch=16 train_loss=1.87547 train_acc=0.74286 val_loss=1.90668 val_acc=0.58800 time=0.00258\n",
            "epoch=17 train_loss=1.87733 train_acc=0.70714 val_loss=1.90390 val_acc=0.59200 time=0.00263\n",
            "epoch=18 train_loss=1.86340 train_acc=0.76429 val_loss=1.90097 val_acc=0.59800 time=0.00279\n",
            "epoch=19 train_loss=1.85134 train_acc=0.75000 val_loss=1.89813 val_acc=0.60000 time=0.00283\n",
            "epoch=20 train_loss=1.85945 train_acc=0.72143 val_loss=1.89512 val_acc=0.59800 time=0.00263\n",
            "epoch=21 train_loss=1.84638 train_acc=0.73571 val_loss=1.89196 val_acc=0.60400 time=0.00261\n",
            "epoch=22 train_loss=1.84945 train_acc=0.70000 val_loss=1.88864 val_acc=0.61400 time=0.00259\n",
            "epoch=23 train_loss=1.83424 train_acc=0.69286 val_loss=1.88518 val_acc=0.61800 time=0.00270\n",
            "epoch=24 train_loss=1.82116 train_acc=0.75714 val_loss=1.88169 val_acc=0.62200 time=0.00261\n",
            "epoch=25 train_loss=1.82467 train_acc=0.74286 val_loss=1.87816 val_acc=0.62400 time=0.00260\n",
            "epoch=26 train_loss=1.81514 train_acc=0.68571 val_loss=1.87455 val_acc=0.62800 time=0.00258\n",
            "epoch=27 train_loss=1.79158 train_acc=0.73571 val_loss=1.87085 val_acc=0.62800 time=0.00257\n",
            "epoch=28 train_loss=1.79450 train_acc=0.72857 val_loss=1.86706 val_acc=0.63400 time=0.00262\n",
            "epoch=29 train_loss=1.79698 train_acc=0.69286 val_loss=1.86329 val_acc=0.63600 time=0.00259\n",
            "epoch=30 train_loss=1.76971 train_acc=0.75000 val_loss=1.85950 val_acc=0.63600 time=0.00268\n",
            "epoch=31 train_loss=1.79795 train_acc=0.74286 val_loss=1.85571 val_acc=0.63800 time=0.00274\n",
            "epoch=32 train_loss=1.76484 train_acc=0.72143 val_loss=1.85192 val_acc=0.64400 time=0.00260\n",
            "epoch=33 train_loss=1.77139 train_acc=0.75714 val_loss=1.84828 val_acc=0.64200 time=0.00258\n",
            "epoch=34 train_loss=1.75219 train_acc=0.74286 val_loss=1.84463 val_acc=0.64600 time=0.00258\n",
            "epoch=35 train_loss=1.72142 train_acc=0.75000 val_loss=1.84100 val_acc=0.64600 time=0.00263\n",
            "epoch=36 train_loss=1.73308 train_acc=0.72143 val_loss=1.83753 val_acc=0.64600 time=0.00260\n",
            "epoch=37 train_loss=1.73575 train_acc=0.80714 val_loss=1.83405 val_acc=0.64800 time=0.00259\n",
            "epoch=38 train_loss=1.70879 train_acc=0.79286 val_loss=1.83050 val_acc=0.65000 time=0.00258\n",
            "epoch=39 train_loss=1.70652 train_acc=0.77143 val_loss=1.82670 val_acc=0.64600 time=0.00260\n",
            "epoch=40 train_loss=1.69285 train_acc=0.72857 val_loss=1.82284 val_acc=0.64800 time=0.00260\n",
            "epoch=41 train_loss=1.69996 train_acc=0.74286 val_loss=1.81902 val_acc=0.64200 time=0.00258\n",
            "epoch=42 train_loss=1.67540 train_acc=0.70714 val_loss=1.81513 val_acc=0.64200 time=0.00256\n",
            "epoch=43 train_loss=1.65363 train_acc=0.73571 val_loss=1.81104 val_acc=0.64400 time=0.00263\n",
            "epoch=44 train_loss=1.66432 train_acc=0.81429 val_loss=1.80697 val_acc=0.64400 time=0.00256\n",
            "epoch=45 train_loss=1.63530 train_acc=0.77857 val_loss=1.80262 val_acc=0.64600 time=0.00257\n",
            "epoch=46 train_loss=1.64767 train_acc=0.76429 val_loss=1.79820 val_acc=0.65000 time=0.00259\n",
            "epoch=47 train_loss=1.63371 train_acc=0.80714 val_loss=1.79372 val_acc=0.65000 time=0.00258\n",
            "epoch=48 train_loss=1.61195 train_acc=0.73571 val_loss=1.78929 val_acc=0.65000 time=0.00259\n",
            "epoch=49 train_loss=1.62139 train_acc=0.79286 val_loss=1.78473 val_acc=0.65000 time=0.00262\n",
            "epoch=50 train_loss=1.63351 train_acc=0.78571 val_loss=1.78009 val_acc=0.65000 time=0.00260\n",
            "epoch=51 train_loss=1.57045 train_acc=0.78571 val_loss=1.77528 val_acc=0.65200 time=0.00262\n",
            "epoch=52 train_loss=1.60672 train_acc=0.74286 val_loss=1.77037 val_acc=0.65200 time=0.00270\n",
            "epoch=53 train_loss=1.57470 train_acc=0.75000 val_loss=1.76540 val_acc=0.65400 time=0.00275\n",
            "epoch=54 train_loss=1.51489 train_acc=0.82857 val_loss=1.76034 val_acc=0.65400 time=0.00292\n",
            "epoch=55 train_loss=1.55845 train_acc=0.79286 val_loss=1.75532 val_acc=0.65200 time=0.00353\n",
            "epoch=56 train_loss=1.52614 train_acc=0.78571 val_loss=1.75044 val_acc=0.65600 time=0.00272\n",
            "epoch=57 train_loss=1.50924 train_acc=0.80714 val_loss=1.74570 val_acc=0.66000 time=0.00276\n",
            "epoch=58 train_loss=1.53363 train_acc=0.82143 val_loss=1.74118 val_acc=0.66200 time=0.00276\n",
            "epoch=59 train_loss=1.52100 train_acc=0.75000 val_loss=1.73686 val_acc=0.65800 time=0.00270\n",
            "epoch=60 train_loss=1.49886 train_acc=0.78571 val_loss=1.73249 val_acc=0.66600 time=0.00269\n",
            "epoch=61 train_loss=1.55388 train_acc=0.80000 val_loss=1.72820 val_acc=0.66000 time=0.00269\n",
            "epoch=62 train_loss=1.48350 train_acc=0.81429 val_loss=1.72410 val_acc=0.66600 time=0.00272\n",
            "epoch=63 train_loss=1.48496 train_acc=0.79286 val_loss=1.71986 val_acc=0.66600 time=0.00271\n",
            "epoch=64 train_loss=1.46284 train_acc=0.80000 val_loss=1.71573 val_acc=0.66600 time=0.00203\n",
            "epoch=65 train_loss=1.45414 train_acc=0.79286 val_loss=1.71155 val_acc=0.67400 time=0.00180\n",
            "epoch=66 train_loss=1.45851 train_acc=0.75714 val_loss=1.70698 val_acc=0.67400 time=0.00188\n",
            "epoch=67 train_loss=1.42518 train_acc=0.79286 val_loss=1.70218 val_acc=0.67400 time=0.00189\n",
            "epoch=68 train_loss=1.41367 train_acc=0.80000 val_loss=1.69708 val_acc=0.67600 time=0.00191\n",
            "epoch=69 train_loss=1.41452 train_acc=0.80000 val_loss=1.69197 val_acc=0.67600 time=0.00188\n",
            "epoch=70 train_loss=1.45117 train_acc=0.79286 val_loss=1.68701 val_acc=0.67600 time=0.00178\n",
            "epoch=71 train_loss=1.38743 train_acc=0.82857 val_loss=1.68218 val_acc=0.67400 time=0.00176\n",
            "epoch=72 train_loss=1.41736 train_acc=0.77143 val_loss=1.67751 val_acc=0.67400 time=0.00185\n",
            "epoch=73 train_loss=1.38403 train_acc=0.82143 val_loss=1.67278 val_acc=0.67600 time=0.00195\n",
            "epoch=74 train_loss=1.39938 train_acc=0.87857 val_loss=1.66798 val_acc=0.67600 time=0.00188\n",
            "epoch=75 train_loss=1.38181 train_acc=0.80714 val_loss=1.66287 val_acc=0.68000 time=0.00190\n",
            "epoch=76 train_loss=1.33230 train_acc=0.83571 val_loss=1.65772 val_acc=0.68400 time=0.00190\n",
            "epoch=77 train_loss=1.33385 train_acc=0.82143 val_loss=1.65247 val_acc=0.68600 time=0.00186\n",
            "epoch=78 train_loss=1.38174 train_acc=0.82857 val_loss=1.64738 val_acc=0.68600 time=0.00188\n",
            "epoch=79 train_loss=1.35522 train_acc=0.85000 val_loss=1.64205 val_acc=0.68400 time=0.00188\n",
            "epoch=80 train_loss=1.33025 train_acc=0.85000 val_loss=1.63656 val_acc=0.68600 time=0.00184\n",
            "epoch=81 train_loss=1.33787 train_acc=0.85000 val_loss=1.63125 val_acc=0.69000 time=0.00185\n",
            "epoch=82 train_loss=1.28857 train_acc=0.84286 val_loss=1.62606 val_acc=0.69000 time=0.00185\n",
            "epoch=83 train_loss=1.34322 train_acc=0.84286 val_loss=1.62112 val_acc=0.68800 time=0.00187\n",
            "epoch=84 train_loss=1.37025 train_acc=0.81429 val_loss=1.61640 val_acc=0.68800 time=0.00315\n",
            "epoch=85 train_loss=1.33706 train_acc=0.82857 val_loss=1.61181 val_acc=0.69000 time=0.00187\n",
            "epoch=86 train_loss=1.26562 train_acc=0.78571 val_loss=1.60689 val_acc=0.69200 time=0.00182\n",
            "epoch=87 train_loss=1.36131 train_acc=0.82857 val_loss=1.60239 val_acc=0.70000 time=0.00177\n",
            "epoch=88 train_loss=1.25039 train_acc=0.90000 val_loss=1.59773 val_acc=0.70200 time=0.00180\n",
            "epoch=89 train_loss=1.21225 train_acc=0.88571 val_loss=1.59333 val_acc=0.70400 time=0.00186\n",
            "epoch=90 train_loss=1.28007 train_acc=0.85000 val_loss=1.58904 val_acc=0.70600 time=0.00190\n",
            "epoch=91 train_loss=1.22280 train_acc=0.86429 val_loss=1.58481 val_acc=0.71200 time=0.00186\n",
            "epoch=92 train_loss=1.16927 train_acc=0.89286 val_loss=1.58038 val_acc=0.71400 time=0.00187\n",
            "epoch=93 train_loss=1.27083 train_acc=0.87143 val_loss=1.57598 val_acc=0.72200 time=0.00197\n",
            "epoch=94 train_loss=1.15910 train_acc=0.85714 val_loss=1.57226 val_acc=0.72800 time=0.00190\n",
            "epoch=95 train_loss=1.25902 train_acc=0.86429 val_loss=1.56817 val_acc=0.72800 time=0.00191\n",
            "epoch=96 train_loss=1.23777 train_acc=0.87143 val_loss=1.56399 val_acc=0.73000 time=0.00189\n",
            "epoch=97 train_loss=1.18281 train_acc=0.90000 val_loss=1.55967 val_acc=0.73400 time=0.00189\n",
            "epoch=98 train_loss=1.21178 train_acc=0.85714 val_loss=1.55526 val_acc=0.73800 time=0.00189\n",
            "epoch=99 train_loss=1.17370 train_acc=0.92143 val_loss=1.55057 val_acc=0.73800 time=0.00187\n",
            "epoch=100 train_loss=1.19571 train_acc=0.90714 val_loss=1.54580 val_acc=0.73600 time=0.00184\n",
            "total training time=0.23733\n",
            "test_loss=1.53434 test_acc=0.75600 time=0.00055\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# author: chinhua\n",
        "#https://blog.csdn.net/zzc_zhuyu/article/details/89929129\n",
        "# 利用硬件实现矩阵乘法加速\n",
        "#矩陣鏈乘法（或矩陣鏈排序問題[1]）是關於以最有效的方式乘以給定矩陣序列的優化問題。問題實際上不是執行乘法，而只是決定所涉及的矩陣乘法的順序。該問題可以使用動態規劃來解決。\n",
        "%%writefile ./cuda_gcn/src/cuda/cuda_kernel.cu\n",
        "\n",
        "#include \"cuda_kernel.cuh\"\n",
        "\n",
        "curandState *devStates;\n",
        "\n",
        "\n",
        "__global__ void cuda_Matmul_forward_kernel(const float *a, const float *b, float *c, const uint m, const uint n, const uint p) {\n",
        "    __shared__ float tileA[TILE_SIZE][TILE_SIZE];\n",
        "    __shared__ float tileB[TILE_SIZE][TILE_SIZE];\n",
        "    int bx = blockIdx.x, by = blockIdx.y, tx = threadIdx.x, ty = threadIdx.y;\n",
        "    int row = by * TILE_SIZE + ty;\n",
        "    int col = bx * TILE_SIZE + tx;\n",
        "\n",
        "    // Initialize partial result\n",
        "    float res_ijk = 0;\n",
        "\n",
        "    for (int i = 0; i < (m-1) / TILE_SIZE + 1; ++i) {\n",
        "        // Load tileA\n",
        "        if (i * TILE_SIZE + ty < m && col < n)\n",
        "            tileA[ty][tx] = a[(i * TILE_SIZE + ty) * n + col];\n",
        "        else\n",
        "            tileA[ty][tx] = 0;\n",
        "\n",
        "        // Load tileB\n",
        "        if (row < n && i * TILE_SIZE + tx < p)\n",
        "            tileB[ty][tx] = b[row * p + i * TILE_SIZE + tx];\n",
        "        else\n",
        "            tileB[ty][tx] = 0;\n",
        "\n",
        "        __syncthreads();\n",
        "\n",
        "        // Compute partial result for each tile\n",
        "        for (int j = 0; j < TILE_SIZE; ++j) {\n",
        "            if (row < n && col < p)\n",
        "                res_ijk += tileA[ty][j] * tileB[j][tx];\n",
        "        }\n",
        "\n",
        "        __syncthreads();\n",
        "    }\n",
        "\n",
        "    // Store the final result\n",
        "    if (row < n && col < p)\n",
        "        c[row * p + col] = res_ijk;\n",
        "}\n",
        "\n",
        "\n",
        "__global__\n",
        "void cuda_Matmul_backward_A_kernel(float *a_grad, const float *b, const float *c_grad, const uint m, const uint n, const uint p) {\n",
        "    __shared__ float tileB[TILE_SIZE][TILE_SIZE];\n",
        "    __shared__ float tileCGrad[TILE_SIZE][TILE_SIZE];\n",
        "    int bx = blockIdx.x, by = blockIdx.y, tx = threadIdx.x, ty = threadIdx.y;\n",
        "    int row = by * TILE_SIZE + ty;\n",
        "    int col = bx * TILE_SIZE + tx;\n",
        "    int range = (p-1) / TILE_SIZE + 1;\n",
        "    float res = 0;\n",
        "    #pragma unroll\n",
        "    for (int i = 0; i < range; i++) {\n",
        "        if (row < m && i * TILE_SIZE + tx < p)\n",
        "            tileCGrad[ty][tx] = c_grad[row * p + i * TILE_SIZE + tx];\n",
        "        else\n",
        "            tileCGrad[ty][tx] = 0;\n",
        "        if (col < n && i * TILE_SIZE + ty < p)\n",
        "            tileB[ty][tx] = b[col * p + i * TILE_SIZE + ty];\n",
        "        else\n",
        "            tileB[ty][tx] = 0;\n",
        "        __syncthreads();\n",
        "\n",
        "        #pragma unroll\n",
        "        for (int j = 0; j < TILE_SIZE; j++)\n",
        "            res += tileCGrad[ty][j] * tileB[j][tx];\n",
        "        __syncthreads();\n",
        "    }\n",
        "    if (row < m && col < n)\n",
        "        a_grad[row * n + col] = res;\n",
        "}\n",
        "\n",
        "__global__\n",
        "void cuda_Matmul_backward_B_kernel(float *b_grad, const float *a, const float *c_grad, const uint m, const uint n, const uint p) {\n",
        "    __shared__ float tileA[TILE_SIZE][TILE_SIZE];\n",
        "    __shared__ float tileCGrad[TILE_SIZE][TILE_SIZE];\n",
        "    int bx = blockIdx.x, by = blockIdx.y, tx = threadIdx.x, ty = threadIdx.y;\n",
        "    int row = by * TILE_SIZE + ty;\n",
        "    int col = bx * TILE_SIZE + tx;\n",
        "    int range = (m-1)/TILE_SIZE+1;\n",
        "    float res = 0;\n",
        "\n",
        "    #pragma unroll\n",
        "    for (int i = 0; i < range; i++) {\n",
        "        if (row < n && i * TILE_SIZE + tx < m)\n",
        "            tileA[ty][tx] = a[(i * TILE_SIZE + tx) * n + row];\n",
        "        else\n",
        "            tileA[ty][tx] = 0;\n",
        "        if (col < p && i * TILE_SIZE + ty < m)\n",
        "            tileCGrad[ty][tx] = c_grad[(i * TILE_SIZE + ty) * p + col];\n",
        "        else\n",
        "            tileCGrad[ty][tx] = 0;\n",
        "        __syncthreads();\n",
        "\n",
        "        #pragma unroll\n",
        "        for (int j = 0; j < TILE_SIZE; j++)\n",
        "            res += tileA[ty][j] * tileCGrad[j][tx];\n",
        "        __syncthreads();\n",
        "    }\n",
        "    if (row < n && col < p)\n",
        "        b_grad[row * p + col] = res;\n",
        "}\n",
        "\n",
        "\n",
        "// sparse matmul\n",
        "__global__\n",
        "void cuda_SparseMatmul_forward_kernel(float *a_in, float *b_in, float *c_in, int *indptr, int *indices, int p) {\n",
        "    int i = blockIdx.x;\n",
        "    int k = threadIdx.x;\n",
        "\n",
        "    #pragma unroll\n",
        "    for (int jj = indptr[i]; jj < indptr[i + 1]; jj++) {\n",
        "        int j = indices[jj];\n",
        "        c_in[i * p + k] += a_in[jj] * b_in[j * p + k];\n",
        "    }\n",
        "}\n",
        "\n",
        "__global__\n",
        "void cuda_SparseMatmul_backward_kernel(float *a_in, float *b_in, float *c_in, int *indptr, int *indices, int p) {\n",
        "    int i = blockIdx.x;\n",
        "    int k = threadIdx.x;\n",
        "\n",
        "    #pragma unroll\n",
        "    for (int jj = indptr[i]; jj < indptr[i + 1]; jj++){\n",
        "        int j = indices[jj];\n",
        "        b_in[j * p + k] += c_in[i * p + k] * a_in[jj];\n",
        "    }\n",
        "}\n",
        "\n",
        "\n",
        "// graph sum\n",
        "__global__\n",
        "void cuda_GraphSum_forward_kernel(float *d_in_data, float *d_out_data, int *d_indptr, int *d_indices, int dim, int numNodes) {\n",
        "    int src = blockIdx.x;\n",
        "    int j = threadIdx.x;\n",
        "\n",
        "    int ptr_src_0 = d_indptr[src];\n",
        "    int ptr_stc_1 = d_indptr[src + 1];\n",
        "\n",
        "    #pragma unroll\n",
        "    for (int i = ptr_src_0; i < ptr_stc_1; i++) {\n",
        "        int dst = d_indices[i];\n",
        "        float coef = 1.0 / sqrtf(\n",
        "                (ptr_stc_1 - ptr_src_0) * (d_indptr[dst + 1] - d_indptr[dst])\n",
        "        );\n",
        "        // This only works for undirected graphs. Should be out[dst] += coef * in[src]]\n",
        "        d_out_data[src * dim + j] += coef * d_in_data[dst * dim + j];\n",
        "    }\n",
        "}\n",
        "\n",
        "__global__\n",
        "void cuda_GraphSum_backward_kernel(float *d_in_grad, float *d_out_grad, int *d_indptr, int *d_indices, int dim, int numNodes) {\n",
        "    int src = blockIdx.x;\n",
        "    int j = threadIdx.x;\n",
        "\n",
        "    int ptr_src_0 = d_indptr[src];\n",
        "    int ptr_stc_1 = d_indptr[src + 1];\n",
        "\n",
        "    #pragma unroll\n",
        "    for (int i = ptr_src_0; i < ptr_stc_1; i++) {\n",
        "        int dst = d_indices[i];\n",
        "        float coef = 1.0 / sqrtf(\n",
        "                (ptr_stc_1 - ptr_src_0) * (d_indptr[dst + 1] - d_indptr[dst])\n",
        "        );\n",
        "        // This only works for undirected graphs. Should be out[dst] += coef * in[src]\n",
        "        d_in_grad[src * dim + j] += coef * d_out_grad[dst * dim + j];\n",
        "    }\n",
        "}\n",
        "\n",
        "\n",
        "// cross entropy\n",
        "__global__\n",
        "void cuda_CrossEntropy_forward_A_kernel(float* logits_data, float* logits_grad, bool training, int num_classes, int* truth, int* count, float* thread_loss, int size) {\n",
        "    int i = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "    if (i >= size) return;\n",
        "    if (truth[i] < 0) {\n",
        "        count[i] = 0;\n",
        "        return;\n",
        "    }\n",
        "    float *logit = &logits_data[i * num_classes];\n",
        "    float max_logit = -1e30, sum_exp = 0;\n",
        "    #pragma unroll\n",
        "    for (int j = 0; j < num_classes; j++)\n",
        "        max_logit = fmax(max_logit, logit[j]);\n",
        "    #pragma unroll\n",
        "    for (int j = 0; j < num_classes; j++) {\n",
        "        logit[j] -= max_logit;\n",
        "        sum_exp += expf(logit[j]);\n",
        "    }\n",
        "    if (training) {\n",
        "        #pragma unroll\n",
        "        for (int j = 0; j < num_classes; j++) {\n",
        "            float prob = expf(logit[j]) / sum_exp;\n",
        "            logits_grad[i * num_classes + j] = prob;\n",
        "        }\n",
        "        logits_grad[i * num_classes + truth[i]] -= 1.0;\n",
        "    }\n",
        "    count[i] = 1;\n",
        "    thread_loss[i] = logf(sum_exp) - logit[truth[i]];\n",
        "}\n",
        "\n",
        "__global__\n",
        "void cuda_CrossEntropy_forward_B_kernel(float *logits_grad, int size, int count) {\n",
        "    int i = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "    if (i < size) logits_grad[i] /= count;\n",
        "}\n",
        "\n",
        "\n",
        "// ReLU\n",
        "__global__\n",
        "void cuda_ReLU_forward_kernel(float *d_in_data, bool *d_mask, const long unsigned int datasize, bool training) {\n",
        "    uint i = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "    if (i >= datasize) return;\n",
        "\n",
        "    bool keep = d_in_data[i] > 0;\n",
        "    if (training) d_mask[i] = keep;\n",
        "    if (!keep) d_in_data[i] = 0;\n",
        "}\n",
        "\n",
        "__global__\n",
        "void cuda_ReLU_backward_kernel(float *d_in_grad, bool *d_mask, long unsigned int datasize) {\n",
        "    uint i = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "    if (i >= datasize) return;\n",
        "    if (!d_mask[i]) d_in_grad[i] = 0;\n",
        "}\n",
        "\n",
        "\n",
        "// Dropout\n",
        "__global__\n",
        "void cuda_Dropout_forward_kernel(float *in, int *mask, curandState *state, const uint size, const float p, const float scale, const bool useMask) {\n",
        "    float x;\n",
        "    bool keep;\n",
        "    int id = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "    if (id < size) {\n",
        "        x = curand_uniform(&state[id % MAX_THREAD_PER_BLOCK]);\n",
        "        keep = x >= p;\n",
        "        in[id] *= keep ? scale : 0;\n",
        "        if (useMask) mask[id] = keep;\n",
        "    }\n",
        "}\n",
        "\n",
        "__global__\n",
        "void cuda_Dropout_backward_kernel(float *in_grad, const int *mask, const uint size, const float scale) {\n",
        "    int id = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "    if (id < size) in_grad[id] *= mask[id] ? scale : 0;\n",
        "}\n",
        "\n",
        "\n",
        "// rand state\n",
        "__global__\n",
        "void cuda_init_rand_kernel(curandState *state) {\n",
        "    int id = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "    curand_init(1234, id, 0, &state[id]);\n",
        "}\n",
        "\n",
        "void cuda_init_random_state(const uint size) {\n",
        "    // malloc\n",
        "    CUDA_CHECK(cudaMalloc((void**) &devStates, size * sizeof(curandState)));\n",
        "\n",
        "    dim3 block((size-1)/MAX_THREAD_PER_BLOCK + 1, 1, 1);\n",
        "    dim3 thread_in_block(MAX_THREAD_PER_BLOCK, 1, 1);\n",
        "\n",
        "    // kernel\n",
        "    cuda_init_rand_kernel<<<block,thread_in_block>>>(devStates);\n",
        "    CUDA_CHECK(cudaGetLastError());\n",
        "    // CUDA_CHECK(cudaDeviceSynchronize());\n",
        "}\n",
        "\n",
        "void cuda_free_random_state() {\n",
        "    // free\n",
        "    CUDA_CHECK(cudaFree(devStates));\n",
        "}\n",
        "\n",
        "\n",
        "// adam\n",
        "__global__\n",
        "void cuda_Adam_step_kernel(float* grad, float* data, float* m, float* v, bool decay, float weight_decay, float beta1, float beta2, float eps, float step_size, int varsize) {\n",
        "    int i = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "\n",
        "    if (i >= varsize) return;\n",
        "\n",
        "    float g = grad[i];\n",
        "    if (decay) g += weight_decay * data[i];\n",
        "    m[i] = beta1 * m[i] + (1.0 - beta1) * g;\n",
        "    v[i] = beta2 * v[i] + (1.0 - beta2) * g * g;\n",
        "    data[i] -= step_size * m[i] / (sqrtf(v[i]) + eps);\n",
        "}\n",
        "\n",
        "__global__\n",
        "void cuda_set_truth_kernel(int *truth, int *data_split, int *data_label, int current_split, int size) {\n",
        "    int id = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "    if (id < size)\n",
        "        truth[id] = data_split[id] == current_split ? data_label[id] : -1;\n",
        "}\n",
        "\n",
        "__global__\n",
        "void cuda_Variable_glorot_kernel(float *data, curandState *state, int size, float scale) {\n",
        "    int id = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "    if (id < size)\n",
        "        data[id] = (curand_uniform(&state[id % MAX_THREAD_PER_BLOCK]) - 0.5) * scale;\n",
        "}\n",
        "\n"
      ],
      "metadata": {
        "id": "aCsCztB1cNpd",
        "outputId": "7dce2615-be31-48ca-fcc0-e4757c3b624e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting ./cuda_gcn/src/cuda/cuda_kernel.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! cd cuda_gcn && make cuda\n",
        "! cd cuda_gcn && ./cuda_gcn cora"
      ],
      "metadata": {
        "id": "n-bEIWwwcfW1",
        "outputId": "7e1f0a37-397f-49a7-e0cf-617b3548bc18",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nvcc -dc -O3 -std=c++11 -Isrc -Isrc/common -Isrc/seq -Isrc/cuda src/cuda/cuda_kernel.cu -o src/cuda/cuda_kernel.o\n",
            "In file included from \u001b[01m\u001b[K/usr/local/cuda/bin/../targets/x86_64-linux/include/thrust/detail/config/config.h:27\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/cuda/bin/../targets/x86_64-linux/include/thrust/detail/config.h:23\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/cuda/bin/../targets/x86_64-linux/include/thrust/extrema.h:23\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Ksrc/cuda/cuda_kernel.cuh:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Ksrc/cuda/cuda_kernel.cu:2\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/cuda/bin/../targets/x86_64-linux/include/thrust/detail/config/cpp_dialect.h:131:13:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[KThrust requires at least C++14. C++11 is deprecated but still supported. C++11 support will be removed in a future release. Define THRUST_IGNORE_DEPRECATED_CPP_DIALECT to suppress this message.\n",
            "  131 |      THRUST_\u001b[01;35m\u001b[KCOMPILER_DEPRECATION_SOFT(C++14, C++11);\u001b[m\u001b[K\n",
            "      |             \u001b[01;35m\u001b[K^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K                                                                                                                                                           \n",
            "In file included from \u001b[01m\u001b[K/usr/local/cuda/bin/../targets/x86_64-linux/include/cub/util_arch.cuh:36\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/cuda/bin/../targets/x86_64-linux/include/cub/detail/device_synchronize.cuh:20\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/cuda/bin/../targets/x86_64-linux/include/thrust/system/cuda/detail/util.h:36\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/cuda/bin/../targets/x86_64-linux/include/thrust/system/cuda/detail/for_each.h:35\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/cuda/bin/../targets/x86_64-linux/include/thrust/system/detail/adl/for_each.h:42\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/cuda/bin/../targets/x86_64-linux/include/thrust/detail/for_each.inl:27\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/cuda/bin/../targets/x86_64-linux/include/thrust/for_each.h:277\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/cuda/bin/../targets/x86_64-linux/include/thrust/system/detail/generic/transform.inl:19\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/cuda/bin/../targets/x86_64-linux/include/thrust/system/detail/generic/transform.h:104\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/cuda/bin/../targets/x86_64-linux/include/thrust/detail/transform.inl:27\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/cuda/bin/../targets/x86_64-linux/include/thrust/transform.h:721\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/cuda/bin/../targets/x86_64-linux/include/thrust/system/detail/generic/copy.inl:23\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/cuda/bin/../targets/x86_64-linux/include/thrust/system/detail/generic/copy.h:57\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/cuda/bin/../targets/x86_64-linux/include/thrust/detail/copy.inl:21\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/cuda/bin/../targets/x86_64-linux/include/thrust/detail/copy.h:90\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/cuda/bin/../targets/x86_64-linux/include/thrust/system/detail/sequential/merge.inl:19\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/cuda/bin/../targets/x86_64-linux/include/thrust/system/detail/sequential/merge.h:78\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/cuda/bin/../targets/x86_64-linux/include/thrust/system/cpp/detail/merge.h:22\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/cuda/bin/../targets/x86_64-linux/include/thrust/system/cpp/execution_policy.h:51\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/cuda/bin/../targets/x86_64-linux/include/thrust/execution_policy.h:32\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/cuda/bin/../targets/x86_64-linux/include/thrust/detail/get_iterator_value.h:20\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/cuda/bin/../targets/x86_64-linux/include/thrust/system/detail/generic/extrema.inl:25\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/cuda/bin/../targets/x86_64-linux/include/thrust/system/detail/generic/extrema.h:87\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/cuda/bin/../targets/x86_64-linux/include/thrust/detail/extrema.inl:22\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/cuda/bin/../targets/x86_64-linux/include/thrust/extrema.h:800\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Ksrc/cuda/cuda_kernel.cuh:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Ksrc/cuda/cuda_kernel.cu:2\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/cuda/bin/../targets/x86_64-linux/include/cub/util_cpp_dialect.cuh:142:13:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[KCUB requires at least C++14. C++11 is deprecated but still supported. C++11 support will be removed in a future release. Define CUB_IGNORE_DEPRECATED_CPP_DIALECT to suppress this message.\n",
            "  142 |      CUB_COM\u001b[01;35m\u001b[KPILER_DEPRECATION_SOFT(C++14, C++11);\u001b[m\u001b[K\n",
            "      |             \u001b[01;35m\u001b[K^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K                                                                                                                                                        \n",
            "In file included from \u001b[01m\u001b[K/usr/local/cuda/bin/../targets/x86_64-linux/include/thrust/detail/config/config.h:27\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/cuda/bin/../targets/x86_64-linux/include/thrust/detail/config.h:23\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/cuda/bin/../targets/x86_64-linux/include/thrust/extrema.h:23\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Ksrc/cuda/cuda_kernel.cuh:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Ksrc/cuda/cuda_kernel.cu:2\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/cuda/bin/../targets/x86_64-linux/include/thrust/detail/config/cpp_dialect.h:131:13:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[KThrust requires at least C++14. C++11 is deprecated but still supported. C++11 support will be removed in a future release. Define THRUST_IGNORE_DEPRECATED_CPP_DIALECT to suppress this message.\n",
            "  131 |      THRUST_\u001b[01;35m\u001b[KCOMPILER_DEPRECATION_SOFT(C++14, C++11);\u001b[m\u001b[K\n",
            "      |             \u001b[01;35m\u001b[K^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K                                                                                                                                                           \n",
            "In file included from \u001b[01m\u001b[K/usr/local/cuda/bin/../targets/x86_64-linux/include/cub/util_arch.cuh:36\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/cuda/bin/../targets/x86_64-linux/include/cub/detail/device_synchronize.cuh:20\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/cuda/bin/../targets/x86_64-linux/include/thrust/system/cuda/detail/util.h:36\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/cuda/bin/../targets/x86_64-linux/include/thrust/system/cuda/detail/for_each.h:35\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/cuda/bin/../targets/x86_64-linux/include/thrust/system/detail/adl/for_each.h:42\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/cuda/bin/../targets/x86_64-linux/include/thrust/detail/for_each.inl:27\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/cuda/bin/../targets/x86_64-linux/include/thrust/for_each.h:277\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/cuda/bin/../targets/x86_64-linux/include/thrust/system/detail/generic/transform.inl:19\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/cuda/bin/../targets/x86_64-linux/include/thrust/system/detail/generic/transform.h:104\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/cuda/bin/../targets/x86_64-linux/include/thrust/detail/transform.inl:27\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/cuda/bin/../targets/x86_64-linux/include/thrust/transform.h:721\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/cuda/bin/../targets/x86_64-linux/include/thrust/system/detail/generic/copy.inl:23\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/cuda/bin/../targets/x86_64-linux/include/thrust/system/detail/generic/copy.h:57\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/cuda/bin/../targets/x86_64-linux/include/thrust/detail/copy.inl:21\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/cuda/bin/../targets/x86_64-linux/include/thrust/detail/copy.h:90\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/cuda/bin/../targets/x86_64-linux/include/thrust/system/detail/sequential/merge.inl:19\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/cuda/bin/../targets/x86_64-linux/include/thrust/system/detail/sequential/merge.h:78\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/cuda/bin/../targets/x86_64-linux/include/thrust/system/cpp/detail/merge.h:22\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/cuda/bin/../targets/x86_64-linux/include/thrust/system/cpp/execution_policy.h:51\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/cuda/bin/../targets/x86_64-linux/include/thrust/execution_policy.h:32\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/cuda/bin/../targets/x86_64-linux/include/thrust/detail/get_iterator_value.h:20\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/cuda/bin/../targets/x86_64-linux/include/thrust/system/detail/generic/extrema.inl:25\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/cuda/bin/../targets/x86_64-linux/include/thrust/system/detail/generic/extrema.h:87\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/cuda/bin/../targets/x86_64-linux/include/thrust/detail/extrema.inl:22\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/cuda/bin/../targets/x86_64-linux/include/thrust/extrema.h:800\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Ksrc/cuda/cuda_kernel.cuh:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Ksrc/cuda/cuda_kernel.cu:2\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/cuda/bin/../targets/x86_64-linux/include/cub/util_cpp_dialect.cuh:142:13:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[KCUB requires at least C++14. C++11 is deprecated but still supported. C++11 support will be removed in a future release. Define CUB_IGNORE_DEPRECATED_CPP_DIALECT to suppress this message.\n",
            "  142 |      CUB_COM\u001b[01;35m\u001b[KPILER_DEPRECATION_SOFT(C++14, C++11);\u001b[m\u001b[K\n",
            "      |             \u001b[01;35m\u001b[K^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K                                                                                                                                                        \n",
            "nvcc -O3 -std=c++11 -Isrc -Isrc/common -Isrc/seq -Isrc/cuda src/cudamain.o src/common/parser.o src/common/timer.o src/seq/gcn.o src/seq/module.o src/seq/optim.o src/seq/rand.o src/seq/sparse.o src/seq/variable.o src/cuda/cuda_gcn.o src/cuda/cuda_kernel.o src/cuda/cuda_module.o src/cuda/cuda_variable.o -o cuda_gcn\n",
            "Parse Graph Succeeded.\n",
            "Parse Node Succeeded.\n",
            "Parse Split Succeeded.\n",
            "RUNNING ON GPU\n",
            "epoch=1 train_loss=1.95410 train_acc=0.88571 val_loss=1.95173 val_acc=0.98800 time=0.00667\n",
            "epoch=2 train_loss=1.95156 train_acc=0.90714 val_loss=1.95027 val_acc=0.99000 time=0.00662\n",
            "epoch=3 train_loss=1.94995 train_acc=0.95000 val_loss=1.94944 val_acc=0.99600 time=0.00660\n",
            "epoch=4 train_loss=1.94899 train_acc=0.94286 val_loss=1.94907 val_acc=0.99600 time=0.00674\n",
            "epoch=5 train_loss=1.94866 train_acc=0.92857 val_loss=1.94906 val_acc=0.99800 time=0.00669\n",
            "epoch=6 train_loss=1.94830 train_acc=0.93571 val_loss=1.94931 val_acc=0.99800 time=0.00663\n",
            "epoch=7 train_loss=1.94843 train_acc=0.95000 val_loss=1.94974 val_acc=0.99800 time=0.00659\n",
            "epoch=8 train_loss=1.94864 train_acc=0.94286 val_loss=1.95033 val_acc=0.99800 time=0.00659\n",
            "epoch=9 train_loss=1.94929 train_acc=0.97143 val_loss=1.95101 val_acc=0.99800 time=0.00663\n",
            "epoch=10 train_loss=1.94983 train_acc=0.94286 val_loss=1.95176 val_acc=0.99800 time=0.00660\n",
            "epoch=11 train_loss=1.95049 train_acc=0.96429 val_loss=1.95258 val_acc=0.99800 time=0.00661\n",
            "epoch=12 train_loss=1.95042 train_acc=0.97143 val_loss=1.95344 val_acc=0.99800 time=0.00668\n",
            "epoch=13 train_loss=1.95209 train_acc=0.95000 val_loss=1.95436 val_acc=0.99800 time=0.00661\n",
            "epoch=14 train_loss=1.95195 train_acc=0.97143 val_loss=1.95530 val_acc=0.99800 time=0.00671\n",
            "epoch=15 train_loss=1.95362 train_acc=0.96429 val_loss=1.95627 val_acc=0.99800 time=0.00676\n",
            "epoch=16 train_loss=1.95401 train_acc=0.95714 val_loss=1.95728 val_acc=0.99800 time=0.00667\n",
            "epoch=17 train_loss=1.95306 train_acc=0.99286 val_loss=1.95832 val_acc=0.99800 time=0.00663\n",
            "epoch=18 train_loss=1.95555 train_acc=0.96429 val_loss=1.95940 val_acc=0.99800 time=0.00660\n",
            "epoch=19 train_loss=1.95558 train_acc=0.96429 val_loss=1.96051 val_acc=0.99800 time=0.00660\n",
            "epoch=20 train_loss=1.95577 train_acc=0.99286 val_loss=1.96160 val_acc=0.99800 time=0.00663\n",
            "epoch=21 train_loss=1.95684 train_acc=0.98571 val_loss=1.96272 val_acc=0.99800 time=0.00659\n",
            "epoch=22 train_loss=1.95846 train_acc=0.95714 val_loss=1.96386 val_acc=0.99800 time=0.00675\n",
            "epoch=23 train_loss=1.96121 train_acc=0.92857 val_loss=1.96504 val_acc=0.99800 time=0.00665\n",
            "epoch=24 train_loss=1.95849 train_acc=0.95714 val_loss=1.96629 val_acc=0.99800 time=0.00662\n",
            "epoch=25 train_loss=1.96068 train_acc=0.97857 val_loss=1.96757 val_acc=0.99800 time=0.00662\n",
            "epoch=26 train_loss=1.96336 train_acc=0.95000 val_loss=1.96887 val_acc=0.99800 time=0.00662\n",
            "epoch=27 train_loss=1.96156 train_acc=0.96429 val_loss=1.97021 val_acc=0.99800 time=0.00663\n",
            "epoch=28 train_loss=1.96386 train_acc=0.94286 val_loss=1.97159 val_acc=0.99800 time=0.00660\n",
            "epoch=29 train_loss=1.96779 train_acc=0.94286 val_loss=1.97300 val_acc=0.99800 time=0.00657\n",
            "epoch=30 train_loss=1.96761 train_acc=0.97143 val_loss=1.97445 val_acc=0.99800 time=0.00661\n",
            "epoch=31 train_loss=1.96729 train_acc=0.97857 val_loss=1.97585 val_acc=0.99800 time=0.00660\n",
            "epoch=32 train_loss=1.96913 train_acc=0.96429 val_loss=1.97726 val_acc=0.99800 time=0.00659\n",
            "epoch=33 train_loss=1.96960 train_acc=0.97143 val_loss=1.97869 val_acc=0.99800 time=0.00661\n",
            "epoch=34 train_loss=1.96697 train_acc=0.97143 val_loss=1.98017 val_acc=0.99800 time=0.00664\n",
            "epoch=35 train_loss=1.97061 train_acc=0.95714 val_loss=1.98173 val_acc=0.99800 time=0.00672\n",
            "epoch=36 train_loss=1.97210 train_acc=0.96429 val_loss=1.98333 val_acc=0.99800 time=0.00663\n",
            "epoch=37 train_loss=1.97446 train_acc=0.96429 val_loss=1.98502 val_acc=0.99800 time=0.00661\n",
            "epoch=38 train_loss=1.97518 train_acc=0.97143 val_loss=1.98678 val_acc=0.99600 time=0.00660\n",
            "epoch=39 train_loss=1.97286 train_acc=0.97857 val_loss=1.98864 val_acc=0.99600 time=0.00659\n",
            "epoch=40 train_loss=1.97665 train_acc=0.97143 val_loss=1.99052 val_acc=0.99600 time=0.00659\n",
            "epoch=41 train_loss=1.97746 train_acc=0.96429 val_loss=1.99245 val_acc=0.99600 time=0.00659\n",
            "epoch=42 train_loss=1.98357 train_acc=0.95714 val_loss=1.99445 val_acc=0.99600 time=0.00414\n",
            "epoch=43 train_loss=1.98382 train_acc=0.98571 val_loss=1.99650 val_acc=0.99600 time=0.00338\n",
            "epoch=44 train_loss=1.98579 train_acc=0.97857 val_loss=1.99857 val_acc=0.99600 time=0.00328\n",
            "epoch=45 train_loss=1.98706 train_acc=0.95714 val_loss=2.00065 val_acc=0.99600 time=0.00331\n",
            "epoch=46 train_loss=1.98740 train_acc=0.98571 val_loss=2.00275 val_acc=0.99600 time=0.00324\n",
            "epoch=47 train_loss=1.99111 train_acc=0.95714 val_loss=2.00485 val_acc=0.99600 time=0.00312\n",
            "epoch=48 train_loss=1.98999 train_acc=0.96429 val_loss=2.00705 val_acc=0.99600 time=0.00312\n",
            "epoch=49 train_loss=1.99310 train_acc=0.95714 val_loss=2.00924 val_acc=0.99600 time=0.00314\n",
            "epoch=50 train_loss=1.98621 train_acc=0.98571 val_loss=2.01147 val_acc=0.99600 time=0.00315\n",
            "epoch=51 train_loss=1.99240 train_acc=0.95000 val_loss=2.01377 val_acc=0.99600 time=0.00311\n",
            "epoch=52 train_loss=1.99869 train_acc=0.97857 val_loss=2.01615 val_acc=0.99600 time=0.00314\n",
            "epoch=53 train_loss=1.99741 train_acc=0.99286 val_loss=2.01858 val_acc=0.99600 time=0.00310\n",
            "epoch=54 train_loss=1.99849 train_acc=0.98571 val_loss=2.02109 val_acc=0.99600 time=0.00311\n",
            "epoch=55 train_loss=2.00765 train_acc=0.95714 val_loss=2.02365 val_acc=0.99600 time=0.00309\n",
            "epoch=56 train_loss=2.00648 train_acc=0.97143 val_loss=2.02625 val_acc=0.99600 time=0.00311\n",
            "epoch=57 train_loss=2.00027 train_acc=0.98571 val_loss=2.02887 val_acc=0.99600 time=0.00311\n",
            "epoch=58 train_loss=2.00550 train_acc=0.97857 val_loss=2.03161 val_acc=0.99600 time=0.00318\n",
            "epoch=59 train_loss=2.00940 train_acc=0.95000 val_loss=2.03440 val_acc=0.99600 time=0.00316\n",
            "epoch=60 train_loss=2.01462 train_acc=0.96429 val_loss=2.03715 val_acc=0.99600 time=0.00311\n",
            "epoch=61 train_loss=2.01451 train_acc=0.97143 val_loss=2.03987 val_acc=0.99600 time=0.00317\n",
            "epoch=62 train_loss=2.02741 train_acc=0.95000 val_loss=2.04264 val_acc=0.99600 time=0.00315\n",
            "epoch=63 train_loss=2.01999 train_acc=0.94286 val_loss=2.04542 val_acc=0.99600 time=0.00310\n",
            "epoch=64 train_loss=2.02385 train_acc=0.97143 val_loss=2.04828 val_acc=0.99600 time=0.00311\n",
            "epoch=65 train_loss=2.03316 train_acc=0.95000 val_loss=2.05113 val_acc=0.99600 time=0.00311\n",
            "epoch=66 train_loss=2.03657 train_acc=0.95000 val_loss=2.05406 val_acc=0.99600 time=0.00311\n",
            "epoch=67 train_loss=2.02748 train_acc=0.95714 val_loss=2.05709 val_acc=0.99600 time=0.00309\n",
            "epoch=68 train_loss=2.03785 train_acc=0.96429 val_loss=2.06020 val_acc=0.99600 time=0.00314\n",
            "epoch=69 train_loss=2.03197 train_acc=0.97143 val_loss=2.06332 val_acc=0.99600 time=0.00311\n",
            "epoch=70 train_loss=2.03304 train_acc=0.97857 val_loss=2.06639 val_acc=0.99600 time=0.00310\n",
            "epoch=71 train_loss=2.04384 train_acc=0.95714 val_loss=2.06956 val_acc=0.99600 time=0.00313\n",
            "epoch=72 train_loss=2.04812 train_acc=0.97143 val_loss=2.07276 val_acc=0.99600 time=0.00310\n",
            "epoch=73 train_loss=2.04999 train_acc=0.97143 val_loss=2.07612 val_acc=0.99600 time=0.00312\n",
            "epoch=74 train_loss=2.05022 train_acc=0.97857 val_loss=2.07949 val_acc=0.99600 time=0.00312\n",
            "epoch=75 train_loss=2.04932 train_acc=0.95714 val_loss=2.08282 val_acc=0.99600 time=0.00309\n",
            "epoch=76 train_loss=2.05445 train_acc=0.96429 val_loss=2.08623 val_acc=0.99600 time=0.00307\n",
            "epoch=77 train_loss=2.05109 train_acc=0.99286 val_loss=2.08977 val_acc=0.99600 time=0.00309\n",
            "epoch=78 train_loss=2.05345 train_acc=0.96429 val_loss=2.09329 val_acc=0.99600 time=0.00308\n",
            "epoch=79 train_loss=2.06115 train_acc=0.95000 val_loss=2.09679 val_acc=0.99600 time=0.00331\n",
            "epoch=80 train_loss=2.05899 train_acc=0.97857 val_loss=2.10019 val_acc=0.99600 time=0.00323\n",
            "epoch=81 train_loss=2.07335 train_acc=0.96429 val_loss=2.10369 val_acc=0.99600 time=0.00317\n",
            "epoch=82 train_loss=2.07168 train_acc=0.96429 val_loss=2.10721 val_acc=0.99600 time=0.00320\n",
            "epoch=83 train_loss=2.06576 train_acc=0.97857 val_loss=2.11081 val_acc=0.99600 time=0.00309\n",
            "epoch=84 train_loss=2.08238 train_acc=0.95000 val_loss=2.11434 val_acc=0.99600 time=0.00308\n",
            "epoch=85 train_loss=2.09071 train_acc=0.94286 val_loss=2.11793 val_acc=0.99600 time=0.00308\n",
            "epoch=86 train_loss=2.07247 train_acc=0.96429 val_loss=2.12170 val_acc=0.99600 time=0.00307\n",
            "epoch=87 train_loss=2.09444 train_acc=0.97143 val_loss=2.12546 val_acc=0.99600 time=0.00308\n",
            "epoch=88 train_loss=2.07801 train_acc=0.98571 val_loss=2.12931 val_acc=0.99600 time=0.00310\n",
            "epoch=89 train_loss=2.09655 train_acc=0.97857 val_loss=2.13325 val_acc=0.99600 time=0.00310\n",
            "epoch=90 train_loss=2.08574 train_acc=0.96429 val_loss=2.13738 val_acc=0.99600 time=0.00313\n",
            "epoch=91 train_loss=2.10296 train_acc=0.97143 val_loss=2.14161 val_acc=0.99600 time=0.00310\n",
            "epoch=92 train_loss=2.09021 train_acc=0.99286 val_loss=2.14609 val_acc=0.99600 time=0.00310\n",
            "epoch=93 train_loss=2.09036 train_acc=0.99286 val_loss=2.15072 val_acc=0.99600 time=0.00309\n",
            "epoch=94 train_loss=2.08343 train_acc=0.98571 val_loss=2.15552 val_acc=0.99600 time=0.00308\n",
            "epoch=95 train_loss=2.12310 train_acc=0.96429 val_loss=2.16016 val_acc=0.99600 time=0.00307\n",
            "epoch=96 train_loss=2.10820 train_acc=0.97143 val_loss=2.16484 val_acc=0.99600 time=0.00309\n",
            "epoch=97 train_loss=2.11830 train_acc=0.98571 val_loss=2.16965 val_acc=0.99600 time=0.00310\n",
            "epoch=98 train_loss=2.13406 train_acc=0.95000 val_loss=2.17432 val_acc=0.99600 time=0.00308\n",
            "epoch=99 train_loss=2.12507 train_acc=0.97143 val_loss=2.17888 val_acc=0.99600 time=0.00307\n",
            "epoch=100 train_loss=2.12059 train_acc=0.97857 val_loss=2.18356 val_acc=0.99600 time=0.00314\n",
            "total training time=0.45754\n",
            "test_loss=2.18362 test_acc=0.99500 time=0.00127\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# author: chinhua\n",
        "#https://blog.csdn.net/zzc_zhuyu/article/details/89929129\n",
        "# 利用硬件实现矩阵乘法加速\n",
        "#矩陣鏈乘法（或矩陣鏈排序問題[1]）是關於以最有效的方式乘以給定矩陣序列的優化問題。問題實際上不是執行乘法，而只是決定所涉及的矩陣乘法的順序。該問題可以使用動態規劃來解決。\n",
        "%%writefile ./cuda_gcn/src/cuda/cuda_kernel.cu\n",
        "\n",
        "#include \"cuda_kernel.cuh\"\n",
        "\n",
        "curandState *devStates;\n",
        "\n",
        "\n",
        "__global__ void cuda_Matmul_forward_kernel(const float *a, const float *b, float *c, const uint m, const uint n, const uint p) {\n",
        "    __shared__ float tileA[TILE_SIZE][TILE_SIZE];\n",
        "    __shared__ float tileB[TILE_SIZE][TILE_SIZE];\n",
        "    int bx = blockIdx.x, by = blockIdx.y, tx = threadIdx.x, ty = threadIdx.y;\n",
        "    int row = by * TILE_SIZE + ty;\n",
        "    int col = bx * TILE_SIZE + tx;\n",
        "\n",
        "    // Initialize partial result\n",
        "    float res_ijk = 0;\n",
        "\n",
        "    for (int i = 0; i < (m-1) / TILE_SIZE + 1; ++i) {\n",
        "        // Load tileA\n",
        "        if (row < m && i * TILE_SIZE + tx < n)\n",
        "            tileA[ty][tx] = a[row * n + i * TILE_SIZE + tx];\n",
        "        else\n",
        "            tileA[ty][tx] = 0;\n",
        "\n",
        "        // Load tileB\n",
        "        if (i * TILE_SIZE + ty < n && col < p)\n",
        "            tileB[ty][tx] = b[(i * TILE_SIZE + ty) * p + col];\n",
        "        else\n",
        "            tileB[ty][tx] = 0;\n",
        "\n",
        "        __syncthreads();\n",
        "\n",
        "        // Compute partial result for each tile\n",
        "        for (int k = 0; k < TILE_SIZE; ++k) {\n",
        "            if (row < m && col < p)\n",
        "                res_ijk += tileA[ty][k] * tileB[k][tx];\n",
        "        }\n",
        "\n",
        "        __syncthreads();\n",
        "    }\n",
        "\n",
        "    // Store the final result\n",
        "    if (row < m && col < p)\n",
        "        c[row * p + col] = res_ijk;\n",
        "}\n",
        "\n",
        "\n",
        "\n",
        "__global__\n",
        "void cuda_Matmul_backward_A_kernel(float *a_grad, const float *b, const float *c_grad, const uint m, const uint n, const uint p) {\n",
        "    __shared__ float tileB[TILE_SIZE][TILE_SIZE];\n",
        "    __shared__ float tileCGrad[TILE_SIZE][TILE_SIZE];\n",
        "    int bx = blockIdx.x, by = blockIdx.y, tx = threadIdx.x, ty = threadIdx.y;\n",
        "    int row = by * TILE_SIZE + ty;\n",
        "    int col = bx * TILE_SIZE + tx;\n",
        "    int range = (p-1) / TILE_SIZE + 1;\n",
        "    float res = 0;\n",
        "    #pragma unroll\n",
        "    for (int i = 0; i < range; i++) {\n",
        "        if (row < m && i * TILE_SIZE + tx < p)\n",
        "            tileCGrad[ty][tx] = c_grad[row * p + i * TILE_SIZE + tx];\n",
        "        else\n",
        "            tileCGrad[ty][tx] = 0;\n",
        "        if (col < n && i * TILE_SIZE + ty < p)\n",
        "            tileB[ty][tx] = b[col * p + i * TILE_SIZE + ty];\n",
        "        else\n",
        "            tileB[ty][tx] = 0;\n",
        "        __syncthreads();\n",
        "\n",
        "        #pragma unroll\n",
        "        for (int j = 0; j < TILE_SIZE; j++)\n",
        "            res += tileCGrad[ty][j] * tileB[j][tx];\n",
        "        __syncthreads();\n",
        "    }\n",
        "    if (row < m && col < n)\n",
        "        a_grad[row * n + col] = res;\n",
        "}\n",
        "\n",
        "__global__\n",
        "void cuda_Matmul_backward_B_kernel(float *b_grad, const float *a, const float *c_grad, const uint m, const uint n, const uint p) {\n",
        "    __shared__ float tileA[TILE_SIZE][TILE_SIZE];\n",
        "    __shared__ float tileCGrad[TILE_SIZE][TILE_SIZE];\n",
        "    int bx = blockIdx.x, by = blockIdx.y, tx = threadIdx.x, ty = threadIdx.y;\n",
        "    int row = by * TILE_SIZE + ty;\n",
        "    int col = bx * TILE_SIZE + tx;\n",
        "    int range = (m-1)/TILE_SIZE+1;\n",
        "    float res = 0;\n",
        "\n",
        "    #pragma unroll\n",
        "    for (int i = 0; i < range; i++) {\n",
        "        if (row < n && i * TILE_SIZE + tx < m)\n",
        "            tileA[ty][tx] = a[(i * TILE_SIZE + tx) * n + row];\n",
        "        else\n",
        "            tileA[ty][tx] = 0;\n",
        "        if (col < p && i * TILE_SIZE + ty < m)\n",
        "            tileCGrad[ty][tx] = c_grad[(i * TILE_SIZE + ty) * p + col];\n",
        "        else\n",
        "            tileCGrad[ty][tx] = 0;\n",
        "        __syncthreads();\n",
        "\n",
        "        #pragma unroll\n",
        "        for (int j = 0; j < TILE_SIZE; j++)\n",
        "            res += tileA[ty][j] * tileCGrad[j][tx];\n",
        "        __syncthreads();\n",
        "    }\n",
        "    if (row < n && col < p)\n",
        "        b_grad[row * p + col] = res;\n",
        "}\n",
        "\n",
        "\n",
        "// sparse matmul\n",
        "__global__\n",
        "void cuda_SparseMatmul_forward_kernel(float *a_in, float *b_in, float *c_in, int *indptr, int *indices, int p) {\n",
        "    int i = blockIdx.x;\n",
        "    int k = threadIdx.x;\n",
        "\n",
        "    #pragma unroll\n",
        "    for (int jj = indptr[i]; jj < indptr[i + 1]; jj++) {\n",
        "        int j = indices[jj];\n",
        "        c_in[i * p + k] += a_in[jj] * b_in[j * p + k];\n",
        "    }\n",
        "}\n",
        "\n",
        "__global__\n",
        "void cuda_SparseMatmul_backward_kernel(float *a_in, float *b_in, float *c_in, int *indptr, int *indices, int p) {\n",
        "    int i = blockIdx.x;\n",
        "    int k = threadIdx.x;\n",
        "\n",
        "    #pragma unroll\n",
        "    for (int jj = indptr[i]; jj < indptr[i + 1]; jj++){\n",
        "        int j = indices[jj];\n",
        "        b_in[j * p + k] += c_in[i * p + k] * a_in[jj];\n",
        "    }\n",
        "}\n",
        "\n",
        "\n",
        "// graph sum\n",
        "__global__\n",
        "void cuda_GraphSum_forward_kernel(float *d_in_data, float *d_out_data, int *d_indptr, int *d_indices, int dim, int numNodes) {\n",
        "    int src = blockIdx.x;\n",
        "    int j = threadIdx.x;\n",
        "\n",
        "    int ptr_src_0 = d_indptr[src];\n",
        "    int ptr_stc_1 = d_indptr[src + 1];\n",
        "\n",
        "    #pragma unroll\n",
        "    for (int i = ptr_src_0; i < ptr_stc_1; i++) {\n",
        "        int dst = d_indices[i];\n",
        "        float coef = 1.0 / sqrtf(\n",
        "                (ptr_stc_1 - ptr_src_0) * (d_indptr[dst + 1] - d_indptr[dst])\n",
        "        );\n",
        "        // This only works for undirected graphs. Should be out[dst] += coef * in[src]]\n",
        "        d_out_data[src * dim + j] += coef * d_in_data[dst * dim + j];\n",
        "    }\n",
        "}\n",
        "\n",
        "__global__\n",
        "void cuda_GraphSum_backward_kernel(float *d_in_grad, float *d_out_grad, int *d_indptr, int *d_indices, int dim, int numNodes) {\n",
        "    int src = blockIdx.x;\n",
        "    int j = threadIdx.x;\n",
        "\n",
        "    int ptr_src_0 = d_indptr[src];\n",
        "    int ptr_stc_1 = d_indptr[src + 1];\n",
        "\n",
        "    #pragma unroll\n",
        "    for (int i = ptr_src_0; i < ptr_stc_1; i++) {\n",
        "        int dst = d_indices[i];\n",
        "        float coef = 1.0 / sqrtf(\n",
        "                (ptr_stc_1 - ptr_src_0) * (d_indptr[dst + 1] - d_indptr[dst])\n",
        "        );\n",
        "        // This only works for undirected graphs. Should be out[dst] += coef * in[src]\n",
        "        d_in_grad[src * dim + j] += coef * d_out_grad[dst * dim + j];\n",
        "    }\n",
        "}\n",
        "\n",
        "\n",
        "// cross entropy\n",
        "__global__\n",
        "void cuda_CrossEntropy_forward_A_kernel(float* logits_data, float* logits_grad, bool training, int num_classes, int* truth, int* count, float* thread_loss, int size) {\n",
        "    int i = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "    if (i >= size) return;\n",
        "    if (truth[i] < 0) {\n",
        "        count[i] = 0;\n",
        "        return;\n",
        "    }\n",
        "    float *logit = &logits_data[i * num_classes];\n",
        "    float max_logit = -1e30, sum_exp = 0;\n",
        "    #pragma unroll\n",
        "    for (int j = 0; j < num_classes; j++)\n",
        "        max_logit = fmax(max_logit, logit[j]);\n",
        "    #pragma unroll\n",
        "    for (int j = 0; j < num_classes; j++) {\n",
        "        logit[j] -= max_logit;\n",
        "        sum_exp += expf(logit[j]);\n",
        "    }\n",
        "    if (training) {\n",
        "        #pragma unroll\n",
        "        for (int j = 0; j < num_classes; j++) {\n",
        "            float prob = expf(logit[j]) / sum_exp;\n",
        "            logits_grad[i * num_classes + j] = prob;\n",
        "        }\n",
        "        logits_grad[i * num_classes + truth[i]] -= 1.0;\n",
        "    }\n",
        "    count[i] = 1;\n",
        "    thread_loss[i] = logf(sum_exp) - logit[truth[i]];\n",
        "}\n",
        "\n",
        "__global__\n",
        "void cuda_CrossEntropy_forward_B_kernel(float *logits_grad, int size, int count) {\n",
        "    int i = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "    if (i < size) logits_grad[i] /= count;\n",
        "}\n",
        "\n",
        "\n",
        "// ReLU\n",
        "__global__\n",
        "void cuda_ReLU_forward_kernel(float *d_in_data, bool *d_mask, const long unsigned int datasize, bool training) {\n",
        "    uint i = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "    if (i >= datasize) return;\n",
        "\n",
        "    bool keep = d_in_data[i] > 0;\n",
        "    if (training) d_mask[i] = keep;\n",
        "    if (!keep) d_in_data[i] = 0;\n",
        "}\n",
        "\n",
        "__global__\n",
        "void cuda_ReLU_backward_kernel(float *d_in_grad, bool *d_mask, long unsigned int datasize) {\n",
        "    uint i = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "    if (i >= datasize) return;\n",
        "    if (!d_mask[i]) d_in_grad[i] = 0;\n",
        "}\n",
        "\n",
        "\n",
        "// Dropout\n",
        "__global__\n",
        "void cuda_Dropout_forward_kernel(float *in, int *mask, curandState *state, const uint size, const float p, const float scale, const bool useMask) {\n",
        "    float x;\n",
        "    bool keep;\n",
        "    int id = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "    if (id < size) {\n",
        "        x = curand_uniform(&state[id % MAX_THREAD_PER_BLOCK]);\n",
        "        keep = x >= p;\n",
        "        in[id] *= keep ? scale : 0;\n",
        "        if (useMask) mask[id] = keep;\n",
        "    }\n",
        "}\n",
        "\n",
        "__global__\n",
        "void cuda_Dropout_backward_kernel(float *in_grad, const int *mask, const uint size, const float scale) {\n",
        "    int id = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "    if (id < size) in_grad[id] *= mask[id] ? scale : 0;\n",
        "}\n",
        "\n",
        "\n",
        "// rand state\n",
        "__global__\n",
        "void cuda_init_rand_kernel(curandState *state) {\n",
        "    int id = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "    curand_init(1234, id, 0, &state[id]);\n",
        "}\n",
        "\n",
        "void cuda_init_random_state(const uint size) {\n",
        "    // malloc\n",
        "    CUDA_CHECK(cudaMalloc((void**) &devStates, size * sizeof(curandState)));\n",
        "\n",
        "    dim3 block((size-1)/MAX_THREAD_PER_BLOCK + 1, 1, 1);\n",
        "    dim3 thread_in_block(MAX_THREAD_PER_BLOCK, 1, 1);\n",
        "\n",
        "    // kernel\n",
        "    cuda_init_rand_kernel<<<block,thread_in_block>>>(devStates);\n",
        "    CUDA_CHECK(cudaGetLastError());\n",
        "    // CUDA_CHECK(cudaDeviceSynchronize());\n",
        "}\n",
        "\n",
        "void cuda_free_random_state() {\n",
        "    // free\n",
        "    CUDA_CHECK(cudaFree(devStates));\n",
        "}\n",
        "\n",
        "\n",
        "// adam\n",
        "__global__\n",
        "void cuda_Adam_step_kernel(float* grad, float* data, float* m, float* v, bool decay, float weight_decay, float beta1, float beta2, float eps, float step_size, int varsize) {\n",
        "    int i = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "\n",
        "    if (i >= varsize) return;\n",
        "\n",
        "    float g = grad[i];\n",
        "    if (decay) g += weight_decay * data[i];\n",
        "    m[i] = beta1 * m[i] + (1.0 - beta1) * g;\n",
        "    v[i] = beta2 * v[i] + (1.0 - beta2) * g * g;\n",
        "    data[i] -= step_size * m[i] / (sqrtf(v[i]) + eps);\n",
        "}\n",
        "\n",
        "__global__\n",
        "void cuda_set_truth_kernel(int *truth, int *data_split, int *data_label, int current_split, int size) {\n",
        "    int id = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "    if (id < size)\n",
        "        truth[id] = data_split[id] == current_split ? data_label[id] : -1;\n",
        "}\n",
        "\n",
        "__global__\n",
        "void cuda_Variable_glorot_kernel(float *data, curandState *state, int size, float scale) {\n",
        "    int id = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "    if (id < size)\n",
        "        data[id] = (curand_uniform(&state[id % MAX_THREAD_PER_BLOCK]) - 0.5) * scale;\n",
        "}\n",
        "\n"
      ],
      "metadata": {
        "id": "u84xcXYTeiFs",
        "outputId": "95f0e8a9-3495-4e87-8544-b0c4def465be",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting ./cuda_gcn/src/cuda/cuda_kernel.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! cd cuda_gcn && make cuda\n",
        "! cd cuda_gcn && ./cuda_gcn cora"
      ],
      "metadata": {
        "id": "vnRApCbZeplw",
        "outputId": "c3536d37-28eb-4bd1-b6b2-1ba970189e6b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nvcc -dc -O3 -std=c++11 -Isrc -Isrc/common -Isrc/seq -Isrc/cuda src/cuda/cuda_kernel.cu -o src/cuda/cuda_kernel.o\n",
            "In file included from \u001b[01m\u001b[K/usr/local/cuda/bin/../targets/x86_64-linux/include/thrust/detail/config/config.h:27\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/cuda/bin/../targets/x86_64-linux/include/thrust/detail/config.h:23\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/cuda/bin/../targets/x86_64-linux/include/thrust/extrema.h:23\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Ksrc/cuda/cuda_kernel.cuh:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Ksrc/cuda/cuda_kernel.cu:2\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/cuda/bin/../targets/x86_64-linux/include/thrust/detail/config/cpp_dialect.h:131:13:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[KThrust requires at least C++14. C++11 is deprecated but still supported. C++11 support will be removed in a future release. Define THRUST_IGNORE_DEPRECATED_CPP_DIALECT to suppress this message.\n",
            "  131 |      THRUST_\u001b[01;35m\u001b[KCOMPILER_DEPRECATION_SOFT(C++14, C++11);\u001b[m\u001b[K\n",
            "      |             \u001b[01;35m\u001b[K^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K                                                                                                                                                           \n",
            "In file included from \u001b[01m\u001b[K/usr/local/cuda/bin/../targets/x86_64-linux/include/cub/util_arch.cuh:36\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/cuda/bin/../targets/x86_64-linux/include/cub/detail/device_synchronize.cuh:20\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/cuda/bin/../targets/x86_64-linux/include/thrust/system/cuda/detail/util.h:36\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/cuda/bin/../targets/x86_64-linux/include/thrust/system/cuda/detail/for_each.h:35\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/cuda/bin/../targets/x86_64-linux/include/thrust/system/detail/adl/for_each.h:42\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/cuda/bin/../targets/x86_64-linux/include/thrust/detail/for_each.inl:27\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/cuda/bin/../targets/x86_64-linux/include/thrust/for_each.h:277\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/cuda/bin/../targets/x86_64-linux/include/thrust/system/detail/generic/transform.inl:19\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/cuda/bin/../targets/x86_64-linux/include/thrust/system/detail/generic/transform.h:104\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/cuda/bin/../targets/x86_64-linux/include/thrust/detail/transform.inl:27\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/cuda/bin/../targets/x86_64-linux/include/thrust/transform.h:721\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/cuda/bin/../targets/x86_64-linux/include/thrust/system/detail/generic/copy.inl:23\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/cuda/bin/../targets/x86_64-linux/include/thrust/system/detail/generic/copy.h:57\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/cuda/bin/../targets/x86_64-linux/include/thrust/detail/copy.inl:21\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/cuda/bin/../targets/x86_64-linux/include/thrust/detail/copy.h:90\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/cuda/bin/../targets/x86_64-linux/include/thrust/system/detail/sequential/merge.inl:19\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/cuda/bin/../targets/x86_64-linux/include/thrust/system/detail/sequential/merge.h:78\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/cuda/bin/../targets/x86_64-linux/include/thrust/system/cpp/detail/merge.h:22\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/cuda/bin/../targets/x86_64-linux/include/thrust/system/cpp/execution_policy.h:51\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/cuda/bin/../targets/x86_64-linux/include/thrust/execution_policy.h:32\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/cuda/bin/../targets/x86_64-linux/include/thrust/detail/get_iterator_value.h:20\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/cuda/bin/../targets/x86_64-linux/include/thrust/system/detail/generic/extrema.inl:25\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/cuda/bin/../targets/x86_64-linux/include/thrust/system/detail/generic/extrema.h:87\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/cuda/bin/../targets/x86_64-linux/include/thrust/detail/extrema.inl:22\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/cuda/bin/../targets/x86_64-linux/include/thrust/extrema.h:800\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Ksrc/cuda/cuda_kernel.cuh:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Ksrc/cuda/cuda_kernel.cu:2\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/cuda/bin/../targets/x86_64-linux/include/cub/util_cpp_dialect.cuh:142:13:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[KCUB requires at least C++14. C++11 is deprecated but still supported. C++11 support will be removed in a future release. Define CUB_IGNORE_DEPRECATED_CPP_DIALECT to suppress this message.\n",
            "  142 |      CUB_COM\u001b[01;35m\u001b[KPILER_DEPRECATION_SOFT(C++14, C++11);\u001b[m\u001b[K\n",
            "      |             \u001b[01;35m\u001b[K^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K                                                                                                                                                        \n",
            "In file included from \u001b[01m\u001b[K/usr/local/cuda/bin/../targets/x86_64-linux/include/thrust/detail/config/config.h:27\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/cuda/bin/../targets/x86_64-linux/include/thrust/detail/config.h:23\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/cuda/bin/../targets/x86_64-linux/include/thrust/extrema.h:23\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Ksrc/cuda/cuda_kernel.cuh:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Ksrc/cuda/cuda_kernel.cu:2\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/cuda/bin/../targets/x86_64-linux/include/thrust/detail/config/cpp_dialect.h:131:13:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[KThrust requires at least C++14. C++11 is deprecated but still supported. C++11 support will be removed in a future release. Define THRUST_IGNORE_DEPRECATED_CPP_DIALECT to suppress this message.\n",
            "  131 |      THRUST_\u001b[01;35m\u001b[KCOMPILER_DEPRECATION_SOFT(C++14, C++11);\u001b[m\u001b[K\n",
            "      |             \u001b[01;35m\u001b[K^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K                                                                                                                                                           \n",
            "In file included from \u001b[01m\u001b[K/usr/local/cuda/bin/../targets/x86_64-linux/include/cub/util_arch.cuh:36\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/cuda/bin/../targets/x86_64-linux/include/cub/detail/device_synchronize.cuh:20\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/cuda/bin/../targets/x86_64-linux/include/thrust/system/cuda/detail/util.h:36\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/cuda/bin/../targets/x86_64-linux/include/thrust/system/cuda/detail/for_each.h:35\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/cuda/bin/../targets/x86_64-linux/include/thrust/system/detail/adl/for_each.h:42\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/cuda/bin/../targets/x86_64-linux/include/thrust/detail/for_each.inl:27\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/cuda/bin/../targets/x86_64-linux/include/thrust/for_each.h:277\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/cuda/bin/../targets/x86_64-linux/include/thrust/system/detail/generic/transform.inl:19\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/cuda/bin/../targets/x86_64-linux/include/thrust/system/detail/generic/transform.h:104\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/cuda/bin/../targets/x86_64-linux/include/thrust/detail/transform.inl:27\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/cuda/bin/../targets/x86_64-linux/include/thrust/transform.h:721\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/cuda/bin/../targets/x86_64-linux/include/thrust/system/detail/generic/copy.inl:23\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/cuda/bin/../targets/x86_64-linux/include/thrust/system/detail/generic/copy.h:57\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/cuda/bin/../targets/x86_64-linux/include/thrust/detail/copy.inl:21\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/cuda/bin/../targets/x86_64-linux/include/thrust/detail/copy.h:90\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/cuda/bin/../targets/x86_64-linux/include/thrust/system/detail/sequential/merge.inl:19\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/cuda/bin/../targets/x86_64-linux/include/thrust/system/detail/sequential/merge.h:78\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/cuda/bin/../targets/x86_64-linux/include/thrust/system/cpp/detail/merge.h:22\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/cuda/bin/../targets/x86_64-linux/include/thrust/system/cpp/execution_policy.h:51\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/cuda/bin/../targets/x86_64-linux/include/thrust/execution_policy.h:32\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/cuda/bin/../targets/x86_64-linux/include/thrust/detail/get_iterator_value.h:20\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/cuda/bin/../targets/x86_64-linux/include/thrust/system/detail/generic/extrema.inl:25\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/cuda/bin/../targets/x86_64-linux/include/thrust/system/detail/generic/extrema.h:87\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/cuda/bin/../targets/x86_64-linux/include/thrust/detail/extrema.inl:22\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/cuda/bin/../targets/x86_64-linux/include/thrust/extrema.h:800\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Ksrc/cuda/cuda_kernel.cuh:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Ksrc/cuda/cuda_kernel.cu:2\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/cuda/bin/../targets/x86_64-linux/include/cub/util_cpp_dialect.cuh:142:13:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[KCUB requires at least C++14. C++11 is deprecated but still supported. C++11 support will be removed in a future release. Define CUB_IGNORE_DEPRECATED_CPP_DIALECT to suppress this message.\n",
            "  142 |      CUB_COM\u001b[01;35m\u001b[KPILER_DEPRECATION_SOFT(C++14, C++11);\u001b[m\u001b[K\n",
            "      |             \u001b[01;35m\u001b[K^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K                                                                                                                                                        \n",
            "nvcc -O3 -std=c++11 -Isrc -Isrc/common -Isrc/seq -Isrc/cuda src/cudamain.o src/common/parser.o src/common/timer.o src/seq/gcn.o src/seq/module.o src/seq/optim.o src/seq/rand.o src/seq/sparse.o src/seq/variable.o src/cuda/cuda_gcn.o src/cuda/cuda_kernel.o src/cuda/cuda_module.o src/cuda/cuda_variable.o -o cuda_gcn\n",
            "Parse Graph Succeeded.\n",
            "Parse Node Succeeded.\n",
            "Parse Split Succeeded.\n",
            "RUNNING ON GPU\n",
            "epoch=1 train_loss=1.95440 train_acc=0.10000 val_loss=1.95064 val_acc=0.17000 time=0.00659\n",
            "epoch=2 train_loss=1.95014 train_acc=0.20714 val_loss=1.94743 val_acc=0.34200 time=0.00657\n",
            "epoch=3 train_loss=1.94486 train_acc=0.45000 val_loss=1.94457 val_acc=0.50000 time=0.00656\n",
            "epoch=4 train_loss=1.94038 train_acc=0.56429 val_loss=1.94170 val_acc=0.59400 time=0.00656\n",
            "epoch=5 train_loss=1.93756 train_acc=0.62143 val_loss=1.93861 val_acc=0.62000 time=0.00652\n",
            "epoch=6 train_loss=1.92970 train_acc=0.70714 val_loss=1.93550 val_acc=0.61200 time=0.00657\n",
            "epoch=7 train_loss=1.92565 train_acc=0.69286 val_loss=1.93245 val_acc=0.58600 time=0.00655\n",
            "epoch=8 train_loss=1.92125 train_acc=0.69286 val_loss=1.92946 val_acc=0.58800 time=0.00652\n",
            "epoch=9 train_loss=1.91845 train_acc=0.67857 val_loss=1.92651 val_acc=0.58800 time=0.00653\n",
            "epoch=10 train_loss=1.91206 train_acc=0.69286 val_loss=1.92361 val_acc=0.58200 time=0.00664\n",
            "epoch=11 train_loss=1.90572 train_acc=0.74286 val_loss=1.92075 val_acc=0.58400 time=0.00651\n",
            "epoch=12 train_loss=1.90185 train_acc=0.80000 val_loss=1.91785 val_acc=0.58400 time=0.00655\n",
            "epoch=13 train_loss=1.89699 train_acc=0.68571 val_loss=1.91501 val_acc=0.58400 time=0.00651\n",
            "epoch=14 train_loss=1.89437 train_acc=0.70000 val_loss=1.91219 val_acc=0.59000 time=0.00653\n",
            "epoch=15 train_loss=1.88557 train_acc=0.69286 val_loss=1.90935 val_acc=0.59200 time=0.00650\n",
            "epoch=16 train_loss=1.87859 train_acc=0.72857 val_loss=1.90649 val_acc=0.60200 time=0.00653\n",
            "epoch=17 train_loss=1.87799 train_acc=0.70000 val_loss=1.90364 val_acc=0.60200 time=0.00652\n",
            "epoch=18 train_loss=1.86376 train_acc=0.73571 val_loss=1.90071 val_acc=0.59800 time=0.00653\n",
            "epoch=19 train_loss=1.85521 train_acc=0.78571 val_loss=1.89787 val_acc=0.60000 time=0.00653\n",
            "epoch=20 train_loss=1.86039 train_acc=0.71429 val_loss=1.89501 val_acc=0.60000 time=0.00651\n",
            "epoch=21 train_loss=1.84664 train_acc=0.74286 val_loss=1.89222 val_acc=0.60000 time=0.00657\n",
            "epoch=22 train_loss=1.85472 train_acc=0.71429 val_loss=1.88944 val_acc=0.60600 time=0.00652\n",
            "epoch=23 train_loss=1.83713 train_acc=0.65714 val_loss=1.88662 val_acc=0.60800 time=0.00669\n",
            "epoch=24 train_loss=1.82723 train_acc=0.75714 val_loss=1.88366 val_acc=0.61600 time=0.00663\n",
            "epoch=25 train_loss=1.82173 train_acc=0.67857 val_loss=1.88073 val_acc=0.61600 time=0.00658\n",
            "epoch=26 train_loss=1.82124 train_acc=0.70714 val_loss=1.87763 val_acc=0.61800 time=0.00651\n",
            "epoch=27 train_loss=1.79761 train_acc=0.75000 val_loss=1.87433 val_acc=0.61800 time=0.00653\n",
            "epoch=28 train_loss=1.80130 train_acc=0.78571 val_loss=1.87098 val_acc=0.62200 time=0.00651\n",
            "epoch=29 train_loss=1.79805 train_acc=0.71429 val_loss=1.86750 val_acc=0.62200 time=0.00352\n",
            "epoch=30 train_loss=1.78369 train_acc=0.78571 val_loss=1.86393 val_acc=0.62400 time=0.00334\n",
            "epoch=31 train_loss=1.80541 train_acc=0.75714 val_loss=1.86031 val_acc=0.62400 time=0.00333\n",
            "epoch=32 train_loss=1.76253 train_acc=0.72143 val_loss=1.85667 val_acc=0.62000 time=0.00333\n",
            "epoch=33 train_loss=1.77486 train_acc=0.75714 val_loss=1.85296 val_acc=0.62200 time=0.00332\n",
            "epoch=34 train_loss=1.74690 train_acc=0.77143 val_loss=1.84903 val_acc=0.62800 time=0.00337\n",
            "epoch=35 train_loss=1.72374 train_acc=0.75000 val_loss=1.84506 val_acc=0.62800 time=0.00332\n",
            "epoch=36 train_loss=1.73348 train_acc=0.71429 val_loss=1.84096 val_acc=0.63600 time=0.00334\n",
            "epoch=37 train_loss=1.72652 train_acc=0.77143 val_loss=1.83675 val_acc=0.63800 time=0.00333\n",
            "epoch=38 train_loss=1.71306 train_acc=0.77857 val_loss=1.83252 val_acc=0.64000 time=0.00331\n",
            "epoch=39 train_loss=1.71068 train_acc=0.80000 val_loss=1.82805 val_acc=0.64200 time=0.00332\n",
            "epoch=40 train_loss=1.70490 train_acc=0.71429 val_loss=1.82361 val_acc=0.63800 time=0.00333\n",
            "epoch=41 train_loss=1.70586 train_acc=0.75000 val_loss=1.81925 val_acc=0.63800 time=0.00330\n",
            "epoch=42 train_loss=1.67743 train_acc=0.76429 val_loss=1.81483 val_acc=0.63800 time=0.00333\n",
            "epoch=43 train_loss=1.67357 train_acc=0.74286 val_loss=1.81046 val_acc=0.63800 time=0.00331\n",
            "epoch=44 train_loss=1.67113 train_acc=0.80000 val_loss=1.80605 val_acc=0.64600 time=0.00338\n",
            "epoch=45 train_loss=1.62638 train_acc=0.77857 val_loss=1.80156 val_acc=0.65400 time=0.00350\n",
            "epoch=46 train_loss=1.67050 train_acc=0.75714 val_loss=1.79693 val_acc=0.65600 time=0.00346\n",
            "epoch=47 train_loss=1.63684 train_acc=0.77857 val_loss=1.79228 val_acc=0.65600 time=0.00336\n",
            "epoch=48 train_loss=1.62260 train_acc=0.75714 val_loss=1.78757 val_acc=0.66200 time=0.00341\n",
            "epoch=49 train_loss=1.63169 train_acc=0.77857 val_loss=1.78280 val_acc=0.66200 time=0.00337\n",
            "epoch=50 train_loss=1.64255 train_acc=0.79286 val_loss=1.77815 val_acc=0.66600 time=0.00334\n",
            "epoch=51 train_loss=1.55303 train_acc=0.80714 val_loss=1.77344 val_acc=0.66400 time=0.00333\n",
            "epoch=52 train_loss=1.57256 train_acc=0.80714 val_loss=1.76841 val_acc=0.66600 time=0.00333\n",
            "epoch=53 train_loss=1.57217 train_acc=0.76429 val_loss=1.76336 val_acc=0.67200 time=0.00334\n",
            "epoch=54 train_loss=1.55005 train_acc=0.79286 val_loss=1.75822 val_acc=0.67000 time=0.00330\n",
            "epoch=55 train_loss=1.56913 train_acc=0.78571 val_loss=1.75290 val_acc=0.67400 time=0.00331\n",
            "epoch=56 train_loss=1.55102 train_acc=0.78571 val_loss=1.74769 val_acc=0.67400 time=0.00334\n",
            "epoch=57 train_loss=1.54062 train_acc=0.77857 val_loss=1.74269 val_acc=0.67600 time=0.00332\n",
            "epoch=58 train_loss=1.53354 train_acc=0.80714 val_loss=1.73798 val_acc=0.68200 time=0.00333\n",
            "epoch=59 train_loss=1.53140 train_acc=0.79286 val_loss=1.73326 val_acc=0.68600 time=0.00331\n",
            "epoch=60 train_loss=1.51642 train_acc=0.80000 val_loss=1.72849 val_acc=0.68400 time=0.00328\n",
            "epoch=61 train_loss=1.50971 train_acc=0.79286 val_loss=1.72372 val_acc=0.68400 time=0.00329\n",
            "epoch=62 train_loss=1.47093 train_acc=0.82143 val_loss=1.71916 val_acc=0.68600 time=0.00331\n",
            "epoch=63 train_loss=1.49460 train_acc=0.79286 val_loss=1.71475 val_acc=0.68600 time=0.00328\n",
            "epoch=64 train_loss=1.47372 train_acc=0.77143 val_loss=1.71046 val_acc=0.69000 time=0.00328\n",
            "epoch=65 train_loss=1.48208 train_acc=0.77143 val_loss=1.70615 val_acc=0.68400 time=0.00328\n",
            "epoch=66 train_loss=1.43152 train_acc=0.82143 val_loss=1.70169 val_acc=0.68400 time=0.00328\n",
            "epoch=67 train_loss=1.46354 train_acc=0.79286 val_loss=1.69725 val_acc=0.68400 time=0.00328\n",
            "epoch=68 train_loss=1.44131 train_acc=0.81429 val_loss=1.69280 val_acc=0.68600 time=0.00328\n",
            "epoch=69 train_loss=1.43059 train_acc=0.85000 val_loss=1.68820 val_acc=0.68600 time=0.00332\n",
            "epoch=70 train_loss=1.44656 train_acc=0.77857 val_loss=1.68379 val_acc=0.68400 time=0.00331\n",
            "epoch=71 train_loss=1.42496 train_acc=0.82143 val_loss=1.67933 val_acc=0.68800 time=0.00328\n",
            "epoch=72 train_loss=1.37110 train_acc=0.85000 val_loss=1.67473 val_acc=0.68800 time=0.00330\n",
            "epoch=73 train_loss=1.37423 train_acc=0.82143 val_loss=1.67025 val_acc=0.69200 time=0.00328\n",
            "epoch=74 train_loss=1.36517 train_acc=0.84286 val_loss=1.66555 val_acc=0.69400 time=0.00328\n",
            "epoch=75 train_loss=1.40989 train_acc=0.80714 val_loss=1.66074 val_acc=0.69400 time=0.00347\n",
            "epoch=76 train_loss=1.35342 train_acc=0.83571 val_loss=1.65568 val_acc=0.69800 time=0.00348\n",
            "epoch=77 train_loss=1.36208 train_acc=0.80714 val_loss=1.65070 val_acc=0.70000 time=0.00342\n",
            "epoch=78 train_loss=1.38033 train_acc=0.81429 val_loss=1.64565 val_acc=0.70800 time=0.00344\n",
            "epoch=79 train_loss=1.36678 train_acc=0.80714 val_loss=1.64061 val_acc=0.70600 time=0.00333\n",
            "epoch=80 train_loss=1.33447 train_acc=0.87857 val_loss=1.63567 val_acc=0.70600 time=0.00329\n",
            "epoch=81 train_loss=1.35117 train_acc=0.83571 val_loss=1.63100 val_acc=0.70800 time=0.00329\n",
            "epoch=82 train_loss=1.26138 train_acc=0.85000 val_loss=1.62629 val_acc=0.70400 time=0.00328\n",
            "epoch=83 train_loss=1.30388 train_acc=0.82143 val_loss=1.62179 val_acc=0.70400 time=0.00330\n",
            "epoch=84 train_loss=1.35536 train_acc=0.84286 val_loss=1.61739 val_acc=0.70400 time=0.00330\n",
            "epoch=85 train_loss=1.29867 train_acc=0.87143 val_loss=1.61302 val_acc=0.70600 time=0.00328\n",
            "epoch=86 train_loss=1.25019 train_acc=0.79286 val_loss=1.60839 val_acc=0.70800 time=0.00328\n",
            "epoch=87 train_loss=1.35087 train_acc=0.85714 val_loss=1.60391 val_acc=0.70800 time=0.00330\n",
            "epoch=88 train_loss=1.22975 train_acc=0.87857 val_loss=1.59930 val_acc=0.71000 time=0.00329\n",
            "epoch=89 train_loss=1.27143 train_acc=0.85714 val_loss=1.59475 val_acc=0.71000 time=0.00284\n",
            "epoch=90 train_loss=1.25944 train_acc=0.86429 val_loss=1.59046 val_acc=0.71000 time=0.00273\n",
            "epoch=91 train_loss=1.24841 train_acc=0.89286 val_loss=1.58619 val_acc=0.71800 time=0.00273\n",
            "epoch=92 train_loss=1.20144 train_acc=0.87857 val_loss=1.58160 val_acc=0.72600 time=0.00271\n",
            "epoch=93 train_loss=1.19914 train_acc=0.89286 val_loss=1.57695 val_acc=0.72600 time=0.00276\n",
            "epoch=94 train_loss=1.21557 train_acc=0.82857 val_loss=1.57263 val_acc=0.72200 time=0.00271\n",
            "epoch=95 train_loss=1.25434 train_acc=0.85000 val_loss=1.56839 val_acc=0.72800 time=0.00274\n",
            "epoch=96 train_loss=1.16803 train_acc=0.92143 val_loss=1.56411 val_acc=0.72800 time=0.00272\n",
            "epoch=97 train_loss=1.22953 train_acc=0.86429 val_loss=1.55957 val_acc=0.72800 time=0.00271\n",
            "epoch=98 train_loss=1.21595 train_acc=0.84286 val_loss=1.55472 val_acc=0.73000 time=0.00280\n",
            "epoch=99 train_loss=1.19172 train_acc=0.90000 val_loss=1.54978 val_acc=0.73400 time=0.00272\n",
            "epoch=100 train_loss=1.20912 train_acc=0.87143 val_loss=1.54510 val_acc=0.73600 time=0.00288\n",
            "total training time=0.41632\n",
            "test_loss=1.53785 test_acc=0.74800 time=0.00116\n"
          ]
        }
      ]
    }
  ]
}